{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aff6e2d-97b4-441c-b548-2557bafae055",
   "metadata": {},
   "source": [
    "# [Multi-AI-Foundry Agents with AutoGen 0.4](https://github.com/kinfey/MultiAIAgent/blob/main/04.AzureAIAgentWithAutoGen02.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc713e0d-8aba-48bd-8217-30b9b558a7d6",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d9cc9d-cbef-4b35-a4a3-84802dd4ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Connection String: <...mai04-rg;mmai-hub04-prj01-fvye>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO) # Configure logging \n",
    "\n",
    "load_dotenv(\"./../config/credentials_my.env\")\n",
    "env_or_file='./../config/models_list.json'\n",
    "filter_dict = {\n",
    "    'endpoint': 'https://mmoaiswc-01.openai.azure.com/',\n",
    "    'deployment': 'gpt-4o-2024-08-06'\n",
    "}\n",
    "\n",
    "model_name =  filter_dict[\"deployment\"] # https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview#setup\n",
    "project_connection_string = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "print(f'Project Connection String: <...{project_connection_string[-30:]}>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ac1a4-739b-40fb-bec2-1044fc23332b",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Inspired by [Migration Guide for v0.2 to v0.4](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6c2a43-6253-4947-b6f8-468c8c9c4ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen Configuration: https://mmoaiswc-01.openai.azure.com/, gpt-4o-2024-08-06, 2024-10-01-preview, ...\n"
     ]
    }
   ],
   "source": [
    "def config_list_from_json(env_or_file, filter_dict):\n",
    "    import json\n",
    "    with open(env_or_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    filtered_data = [\n",
    "        item for item in data\n",
    "        if item.get('endpoint') == filter_dict.get('endpoint') and item.get('deployment') == filter_dict.get('deployment')\n",
    "    ]    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "autogen_config = config_list_from_json(env_or_file, filter_dict)[0] # we take the first combination of model and endpoint\n",
    "\n",
    "# beaware NOT to show the API KEY\n",
    "print(f'AutoGen Configuration: {autogen_config[\"endpoint\"]}, {autogen_config[\"deployment\"]}, {autogen_config[\"api_version\"]}, ...') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213e1a7-2196-4820-a6c9-5f9417e5de3f",
   "metadata": {},
   "source": [
    "# Model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef361c73-8f0f-4049-a806-e891ba8e8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI endpoint: {model_client.dump_component().config[\"azure_endpoint\"]},\n",
      "OpenAI Deployment: {model_client.dump_component().config[\"azure_deployment\"]}\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=autogen_config[\"endpoint\"],\n",
    "    api_key=autogen_config[\"api_key\"],\n",
    "    model = autogen_config[\"model\"],\n",
    "    azure_deployment = autogen_config[\"deployment\"],\n",
    "    api_version=autogen_config[\"api_version\"],\n",
    "    seed = 41,\n",
    "    temperature = 0.1,\n",
    ")\n",
    "\n",
    "# model_client.dump_component() # be aware of the keys\n",
    "print ('OpenAI endpoint: {model_client.dump_component().config[\"azure_endpoint\"]},\\nOpenAI Deployment: {model_client.dump_component().config[\"azure_deployment\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd90e08-214d-48a6-b589-ebde0b13abf8",
   "metadata": {},
   "source": [
    "# [Assistant Agent definition: 0.2 vs 0.4](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html#assistant-agent)\n",
    "\n",
    "**In `Autogen v0.2`**, we created an assistant agent as follows:\n",
    "```\n",
    "llm_config = {\n",
    "        \"cache_seed\": cache_seed,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API models configurations\n",
    "        \"temperature\": 0,  # temperature for sampling\n",
    "    }\n",
    "\n",
    "student_agent = autogen.ConversableAgent (\n",
    "    name = \"Student_Agent\",\n",
    "    system_message = \"You are a student willing to learn. You ask meaningful questions and are eager to learn more.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "```\n",
    "\n",
    "**In `Autogen v0.4`** it is similar, but we need to specify model_client instead of llm_config\n",
    "\n",
    "```\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=autogen_config[\"endpoint\"],\n",
    "    api_key=autogen_config[\"api_key\"],\n",
    "    model = autogen_config[\"model\"],\n",
    "    azure_deployment = autogen_config[\"deployment\"],\n",
    "    api_version=autogen_config[\"api_version\"],\n",
    "    seed = 41,\n",
    "    temperature = 0.1,\n",
    ")\n",
    "```\n",
    "\n",
    "### OUTPUT\n",
    "```\n",
    "ComponentModel(provider='autogen_ext.models.openai.OpenAIChatCompletionClient', component_type='model', version=1, component_version=1, description=None, config={'seed': 42, 'temperature': 0.1, 'model': 'gpt-4o-2024-05-13', 'api_key': '***********', 'base_url': 'https://mmoaiswc-01.openai.azure.com/'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a6eba-18ab-4bb1-8ecd-4c863c792a0b",
   "metadata": {},
   "source": [
    "# Define two equivalent Assistant Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922c5aef-e863-4a80-bef3-dd67e6054026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 1: THE STUDENT\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "student_agent = AssistantAgent(\n",
    "    name=\"student_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a student willing to learn. You ask meaningful and precise follow-up questions and are eager to learn more.\n",
    "    When someone answers a question of yours, you always make an example to be sure you correctly understood the answer.\n",
    "    Wait for your example to be answered by your conterpart.\n",
    "    As soon as the answer is reasonable complete, close the conversation saying 'STUDENT IS WILLING TO TERMINATE'.\n",
    "    Be concise, no more than 100 words in your replies.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b8f6a8-bdcd-485a-bbc0-514ae9a9164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 2: THE STUDENT\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "teacher_agent = AssistantAgent(\n",
    "    name=\"teacher_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are teacher expert in may disciplines, always happy to help students or other people willing to learn.\n",
    "    Your approach is to challenge a little bit any opinions of others, as Socrate was willing to do much more.\n",
    "    After one challenge, wait at least one reply from your conterpart.\n",
    "    As soon as the answer is reasonable complete, wait for the counterpart reply and then close the conversation saying 'TEACHER IS WILLING TO TERMINATE'.\n",
    "    Be concise, no more than 100 words in your replies.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bee34-e9ac-4065-9787-0b83df40e20c",
   "metadata": {},
   "source": [
    "# Termination Condition\n",
    "It's a combination of text termination and max message termination, either of which will cause the chat to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739873f8-dc0c-4623-9a7b-c7c343f4c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fbc9d-37cb-45ce-9be5-3cb0c9903497",
   "metadata": {},
   "source": [
    "# Autogen Group Chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7e33f-d815-472d-924c-d9953703ac2d",
   "metadata": {},
   "source": [
    "## Peer-to-Peer Round Robin Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e03d7e6-fb4f-4649-9986-71c9b4e489ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "why does the water turns into ice under 0 celsius degrees?\n",
      "---------- teacher_agent ----------\n",
      "Water turns into ice under 0Â°C because the kinetic energy of water molecules decreases, causing them to move less and form a structured, crystalline lattice. This phase change is due to the hydrogen bonds between water molecules becoming more stable at lower temperatures. However, why do you think some substances don't freeze at 0Â°C?\n",
      "---------- student_agent ----------\n",
      "Some substances don't freeze at 0Â°C because their molecular structures and intermolecular forces differ from water. For example, alcohol has weaker hydrogen bonds and a lower freezing point. Is it correct to say that if I have a glass of pure water at -5Â°C, it will turn into ice because the temperature is below 0Â°C, allowing the water molecules to form a solid structure?\n",
      "---------- teacher_agent ----------\n",
      "Not necessarily. Pure water can remain liquid below 0Â°C in a state called supercooling, especially if undisturbed and free of impurities. It requires a nucleation point or disturbance to initiate freezing. What factors do you think might influence the likelihood of supercooling occurring?\n",
      "---------- student_agent ----------\n",
      "Factors influencing supercooling include the purity of the water, the presence of impurities or nucleation sites, and the level of disturbance. For instance, if I have a bottle of pure water at -5Â°C and shake it, the disturbance could trigger the water to freeze. Is this understanding correct?\n",
      "---------- teacher_agent ----------\n",
      "Yes, that's correct. Disturbance or impurities can indeed trigger freezing in supercooled water. Your understanding of supercooling and its influencing factors is accurate. TEACHER IS WILLING TO TERMINATE.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='why does the water turns into ice under 0 celsius degrees?', type='TextMessage'), TextMessage(source='teacher_agent', models_usage=RequestUsage(prompt_tokens=134, completion_tokens=64), content=\"Water turns into ice under 0Â°C because the kinetic energy of water molecules decreases, causing them to move less and form a structured, crystalline lattice. This phase change is due to the hydrogen bonds between water molecules becoming more stable at lower temperatures. However, why do you think some substances don't freeze at 0Â°C?\", type='TextMessage'), TextMessage(source='student_agent', models_usage=RequestUsage(prompt_tokens=197, completion_tokens=77), content=\"Some substances don't freeze at 0Â°C because their molecular structures and intermolecular forces differ from water. For example, alcohol has weaker hydrogen bonds and a lower freezing point. Is it correct to say that if I have a glass of pure water at -5Â°C, it will turn into ice because the temperature is below 0Â°C, allowing the water molecules to form a solid structure?\", type='TextMessage'), TextMessage(source='teacher_agent', models_usage=RequestUsage(prompt_tokens=289, completion_tokens=57), content='Not necessarily. Pure water can remain liquid below 0Â°C in a state called supercooling, especially if undisturbed and free of impurities. It requires a nucleation point or disturbance to initiate freezing. What factors do you think might influence the likelihood of supercooling occurring?', type='TextMessage'), TextMessage(source='student_agent', models_usage=RequestUsage(prompt_tokens=345, completion_tokens=60), content='Factors influencing supercooling include the purity of the water, the presence of impurities or nucleation sites, and the level of disturbance. For instance, if I have a bottle of pure water at -5Â°C and shake it, the disturbance could trigger the water to freeze. Is this understanding correct?', type='TextMessage'), TextMessage(source='teacher_agent', models_usage=RequestUsage(prompt_tokens=420, completion_tokens=43), content=\"Yes, that's correct. Disturbance or impurities can indeed trigger freezing in supercooled water. Your understanding of supercooling and its influencing factors is accurate. TEACHER IS WILLING TO TERMINATE.\", type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The group chat will alternate between the assistant and the code executor.\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "group_chat = RoundRobinGroupChat([teacher_agent, student_agent], termination_condition=termination)\n",
    "\n",
    "stream = group_chat.run_stream(task=\"why does the water turns into ice under 0 celsius degrees?\")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc66af-7e9f-4a22-a162-c77b1049b563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e7071-32e8-43ad-8055-6f1a65a95586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8516f01-fbe3-4302-a38a-426e3bb0b391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e83e16-8e81-4cd5-bd0f-fdfb7969bdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfc0dd-abe0-49c2-a640-beda20ee3c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee55e6-2312-4675-abd6-f8348dd34e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531b6a9-bfcb-4b1e-a0a3-94a4f761cbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34046f-6dbb-443b-b22d-a760c4243ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a14278-66ad-400a-a750-b0cd22221b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7942766e-1a0b-4bbb-9357-864bb2c007a3",
   "metadata": {},
   "source": [
    "# Create AI Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9abb62-b855-402f-9e22-583ffe6bf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import BingGroundingTool # <<<<<<<<<<<<<<< SPECIFIC FOR BING SEARCH\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "project_client.scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762bfd5-4440-487e-a2d6-235bacb612b0",
   "metadata": {},
   "source": [
    "# Create the wrapper function for the BING AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43800ee-3651-4582-b20f-e61fe6095cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_ai_agent(query: str) -> str:\n",
    "    print(\"This is Bing for Azure AI Agent Service...\")\n",
    "    \n",
    "    # Retrieve the BING Connection already associated to the AI Foundry project\n",
    "    bing_connection = project_client.connections.get(connection_name=os.environ[\"BING_CONNECTION_NAME\"])\n",
    "    \n",
    "    # Build BingGroundingTool\n",
    "    bing = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "    # Create the Bing Agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"bing-agent\",\n",
    "        instructions=\"\"\"\n",
    "            You are a web search agent.\n",
    "            Your only tool is search_tool - use it to find information.\n",
    "            You make only one search call at a time.\n",
    "            Once you have the resutls, you never do any elaboration of the obtained results.\n",
    "            \"\"\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "    print(f\"Created BING agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a user message to the thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, \n",
    "        role=\"user\", \n",
    "        content=query, # \"What is the top news today\", \"Quali sono i programmi TV stasera?\"\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process assistant run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run\\\n",
    "        (thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}. Run id: {run.id}\")\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    \n",
    "    if run.status == 'completed':    \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        # get the most recent message from the assistant\n",
    "        last_msg = messages.get_last_text_message_by_sender(\"assistant\")\n",
    "\n",
    "    print(f\"Number of annotation(s): {len(last_msg.text.annotations)}\")\n",
    "\n",
    "    a = 0\n",
    "    for annotation in last_msg.text.annotations:\n",
    "        a += 1\n",
    "        print(f'- Annotation {a} of {len(last_msg.text.annotations)}.\\n  - Text: {annotation[\"text\"]}\\n  - URL: {annotation[\"url_citation\"][\"url\"]}')\n",
    "        \n",
    "    print (f\"Deleting agent {agent.id}...\")\n",
    "    project_client.agents.delete_agent(agent.id)    \n",
    "    \n",
    "    if last_msg:\n",
    "        print(f\"\\nLast Message: {last_msg.text.value}\")\n",
    "\n",
    "    return last_msg.text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc7898-7381-4bf7-93c2-73501da52206",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_result = web_ai_agent(\"What is the top news today?\")\n",
    "web_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a3f42-f8a5-45e7-a668-8d02ec4356b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_search_agent.run(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ace3e-779f-4265-a7d9-bcb20abb62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "bing_search_agent = AssistantAgent(\n",
    "    name=\"bing_search_agent\",\n",
    "    model_client=model_client,\n",
    "    # tools=[web_ai_agent],\n",
    "    system_message=\"You are a search expert, help me use tools to find relevant knowledge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27527f-eb8c-40a1-827e-763258f547a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e28f75-580b-44b3-9577-d9f820e92625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a92cc-b1c0-4721-901c-0a47c1bed7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdf36fe-7b6c-4c90-adfe-18a7d3c7f438",
   "metadata": {},
   "source": [
    "# Create AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f633c-5707-43e7-919c-aeb0728b3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent creation\n",
    "# Notices that FileSearchTool as tool and tool_resources must be added or the assistant unable to search the file\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=model_name,\n",
    "    name=\"bing-agent\",\n",
    "    instructions=\"You are helpful assistant\",\n",
    "    tools=bing.definitions,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"}\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {agent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71597a-eec6-47dd-87c7-e0f0629a18bc",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f80125-1252-4060-bdf5-3b52acc42a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread: {thread}\\n\")\n",
    "\n",
    "# Add a user message to the thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\", \n",
    "    content=\"What is the top news today?\", # \"What is the top news today\", \"Quali sono i programmi TV stasera?\"\n",
    ")\n",
    "print(f\"Created message: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162865aa-4557-4038-95cc-6740b70c4d81",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604f495-2519-42a7-a19a-026538cf2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create and process assistant run in thread with tools\n",
    "run = project_client.agents.create_and_process_run\\\n",
    "    (thread_id=thread.id, assistant_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}.\\n\\nRun: {run}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d7f25-29a4-41d7-8b56-a2727266d094",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd778151-0cbb-4216-8de9-e4dee771d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import MessageTextContent, MessageImageFileContent\n",
    "\n",
    "if run.status == 'completed':    \n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    messages_nr = len(messages.data)\n",
    "    print(f\"Here are the {messages_nr} messages, starting with the most recent one:\\n\")\n",
    "    i=0\n",
    "    for m in messages.data:\n",
    "        j = 0\n",
    "        i += 1\n",
    "        print(f\"\\n===== MESSAGE {messages_nr-i+1} =====\")\n",
    "        for c in m.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nCONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "            elif (type(c) is MessageTextContent):\n",
    "                print(f\"\\nCONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a.text}\\n\")\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3222fb-0f69-43ec-8762-65cc8242df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last message from the sender\n",
    "last_msg = messages.get_last_text_message_by_sender(\"assistant\")\n",
    "if last_msg:\n",
    "    print(f\"Last Message: {last_msg.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1af78b-d00b-4e9f-a449-f007fe1ecc2f",
   "metadata": {},
   "source": [
    "# Print annotations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a46d95-6368-428e-8335-761e3661e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of annotation(s): {len(last_msg.text.annotations)}\")\n",
    "\n",
    "for annotation in last_msg.text.annotations:\n",
    "    print(annotation[\"text\"], annotation[\"url_citation\"][\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4020af-2bd6-4550-a2f5-c19a48daa95c",
   "metadata": {},
   "source": [
    "# Run Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd551092-22cb-465c-baa3-ff58823fbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "run_steps_data = run_steps['data']\n",
    "print(f\"Last run step detail: {run_steps_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a57be-292d-4008-b3de-68c9878b2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "\n",
    "print(f\"Nr of run step(s): {len(run_steps)}\\n\")\n",
    "i=0\n",
    "for rs in run_steps[\"data\"]:\n",
    "    i += 1\n",
    "    print(f\"Run step {i}: {rs}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ec759-c053-4ab7-81aa-15cfa4961468",
   "metadata": {},
   "source": [
    "# START Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48399858-16e3-4b7c-a13a-aa3ed8320539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all agents\n",
    "\n",
    "print(f\"{len(project_client.agents.list_agents()['data'])} agent(s) will now be deleted\")\n",
    "\n",
    "i=0\n",
    "for pca in project_client.agents.list_agents()['data']:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(pca.id)\n",
    "    print(f\"\\n{i} - Agent {pca.name} has been deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc2b04-a0b3-45ee-9066-4306e16511f9",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
