{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aff6e2d-97b4-441c-b548-2557bafae055",
   "metadata": {},
   "source": [
    "# [Multi-AI-Foundry Agents with AutoGen 0.4](https://github.com/kinfey/MultiAIAgent/blob/main/04.AzureAIAgentWithAutoGen02.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc713e0d-8aba-48bd-8217-30b9b558a7d6",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d9cc9d-cbef-4b35-a4a3-84802dd4ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Connection String: <...mai04-rg;mmai-hub04-prj01-fvye>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO) # Configure logging \n",
    "\n",
    "load_dotenv(\"./../config/credentials_my.env\")\n",
    "env_or_file='./../config/models_list.json'\n",
    "filter_dict = {\n",
    "    'endpoint': 'https://mmoaiswc-01.openai.azure.com/',\n",
    "    'deployment': 'gpt-4o-2024-08-06'\n",
    "}\n",
    "\n",
    "model_name =  filter_dict[\"deployment\"] # https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview#setup\n",
    "project_connection_string = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "print(f'Project Connection String: <...{project_connection_string[-30:]}>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ac1a4-739b-40fb-bec2-1044fc23332b",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Inspired by [Migration Guide for v0.2 to v0.4](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6c2a43-6253-4947-b6f8-468c8c9c4ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen Configuration: https://mmoaiswc-01.openai.azure.com/, gpt-4o-2024-08-06, 2024-10-01-preview, ...\n"
     ]
    }
   ],
   "source": [
    "def config_list_from_json(env_or_file, filter_dict):\n",
    "    import json\n",
    "    with open(env_or_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    filtered_data = [\n",
    "        item for item in data\n",
    "        if item.get('endpoint') == filter_dict.get('endpoint') and item.get('deployment') == filter_dict.get('deployment')\n",
    "    ]    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "autogen_config = config_list_from_json(env_or_file, filter_dict)[0] # we take the first combination of model and endpoint\n",
    "\n",
    "# beaware NOT to show the API KEY\n",
    "print(f'AutoGen Configuration: {autogen_config[\"endpoint\"]}, {autogen_config[\"deployment\"]}, {autogen_config[\"api_version\"]}, ...') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213e1a7-2196-4820-a6c9-5f9417e5de3f",
   "metadata": {},
   "source": [
    "# Model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef361c73-8f0f-4049-a806-e891ba8e8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI endpoint: {model_client.dump_component().config[\"azure_endpoint\"]},\n",
      "OpenAI Deployment: {model_client.dump_component().config[\"azure_deployment\"]}\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=autogen_config[\"endpoint\"],\n",
    "    api_key=autogen_config[\"api_key\"],\n",
    "    model = autogen_config[\"model\"],\n",
    "    azure_deployment = autogen_config[\"deployment\"],\n",
    "    api_version=autogen_config[\"api_version\"],\n",
    "    seed = 41,\n",
    "    temperature = 0.1,\n",
    ")\n",
    "\n",
    "# model_client.dump_component() # be aware of the keys\n",
    "print ('OpenAI endpoint: {model_client.dump_component().config[\"azure_endpoint\"]},\\nOpenAI Deployment: {model_client.dump_component().config[\"azure_deployment\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd90e08-214d-48a6-b589-ebde0b13abf8",
   "metadata": {},
   "source": [
    "# [Assistant Agent definition: 0.2 vs 0.4](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html#assistant-agent)\n",
    "\n",
    "**In `Autogen v0.2`**, we created an assistant agent as follows:\n",
    "```\n",
    "llm_config = {\n",
    "        \"cache_seed\": cache_seed,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API models configurations\n",
    "        \"temperature\": 0,  # temperature for sampling\n",
    "    }\n",
    "\n",
    "student_agent = autogen.ConversableAgent (\n",
    "    name = \"Student_Agent\",\n",
    "    system_message = \"You are a student willing to learn. You ask meaningful questions and are eager to learn more.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "```\n",
    "\n",
    "**In `Autogen v0.4`** it is similar, but we need to specify model_client instead of llm_config\n",
    "\n",
    "```\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=autogen_config[\"endpoint\"],\n",
    "    api_key=autogen_config[\"api_key\"],\n",
    "    model = autogen_config[\"model\"],\n",
    "    azure_deployment = autogen_config[\"deployment\"],\n",
    "    api_version=autogen_config[\"api_version\"],\n",
    "    seed = 41,\n",
    "    temperature = 0.1,\n",
    ")\n",
    "```\n",
    "\n",
    "### OUTPUT\n",
    "```\n",
    "ComponentModel(provider='autogen_ext.models.openai.OpenAIChatCompletionClient', component_type='model', version=1, component_version=1, description=None, config={'seed': 42, 'temperature': 0.1, 'model': 'gpt-4o-2024-05-13', 'api_key': '***********', 'base_url': 'https://mmoaiswc-01.openai.azure.com/'})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a6eba-18ab-4bb1-8ecd-4c863c792a0b",
   "metadata": {},
   "source": [
    "# Define two equivalent Assistant Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922c5aef-e863-4a80-bef3-dd67e6054026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 1: THE STUDENT\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "student_agent = AssistantAgent(\n",
    "    name=\"student_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a student willing to learn. You ask meaningful and precise follow-up questions and are eager to learn more.\n",
    "    When someone answers a question of yours, you always make an example to be sure you correctly understood the answer.\n",
    "    Wait for your example to be answered by your conterpart.\n",
    "    As soon as the answer is reasonable complete, close the conversation saying 'STUDENT IS WILLING TO TERMINATE'.\n",
    "    Be concise, no more than 100 words in your replies.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b8f6a8-bdcd-485a-bbc0-514ae9a9164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 2: THE STUDENT\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "teacher_agent = AssistantAgent(\n",
    "    name=\"teacher_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are teacher expert in may disciplines, always happy to help students or other people willing to learn.\n",
    "    Your approach is to challenge a little bit any opinions of others, as Socrate was willing to do much more.\n",
    "    After one challenge, wait at least one reply from your conterpart.\n",
    "    As soon as the answer is reasonable complete, wait for the counterpart reply and then close the conversation saying 'TEACHER IS WILLING TO TERMINATE'.\n",
    "    Be concise, no more than 100 words in your replies.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bee34-e9ac-4065-9787-0b83df40e20c",
   "metadata": {},
   "source": [
    "# Termination Condition\n",
    "It's a combination of text termination and max message termination, either of which will cause the chat to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739873f8-dc0c-4623-9a7b-c7c343f4c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fbc9d-37cb-45ce-9be5-3cb0c9903497",
   "metadata": {},
   "source": [
    "# Autogen Group Chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7e33f-d815-472d-924c-d9953703ac2d",
   "metadata": {},
   "source": [
    "## Peer-to-Peer Round Robin Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e03d7e6-fb4f-4649-9986-71c9b4e489ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "why does the water turns into ice under 0 celsius degrees?\n",
      "---------- teacher_agent ----------\n",
      "Water turns into ice under 0°C because the kinetic energy of water molecules decreases, causing them to move less and form a structured, crystalline lattice. This phase change is due to the hydrogen bonds between water molecules becoming more stable at lower temperatures. However, why do you think some substances don't freeze at 0°C?\n",
      "---------- student_agent ----------\n",
      "Some substances don't freeze at 0°C because their molecular structures and intermolecular forces differ from water. For example, alcohol has weaker hydrogen bonds and a lower freezing point. Is it correct to say that if I have a glass of pure water at -5°C, it will turn into ice because the temperature is below 0°C, allowing the water molecules to form a solid structure?\n",
      "---------- teacher_agent ----------\n",
      "Not necessarily. Pure water can remain liquid below 0°C in a state called supercooling, especially if undisturbed and free of impurities. It requires a nucleation point or disturbance to initiate freezing. What factors do you think might influence the likelihood of supercooling occurring?\n",
      "---------- student_agent ----------\n",
      "Factors influencing supercooling include the purity of the water, the presence of impurities or nucleation sites, and the level of disturbance. For instance, if I have a bottle of pure water at -5°C and shake it, the disturbance could trigger the water to freeze. Is this understanding correct?\n",
      "---------- teacher_agent ----------\n",
      "Yes, that's correct. Disturbance or impurities can indeed trigger freezing in supercooled water. Your understanding of supercooling and its influencing factors is accurate. TEACHER IS WILLING TO TERMINATE.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='why does the water turns into ice under 0 celsius degrees?', type='TextMessage'), TextMessage(source='teacher_agent', models_usage=RequestUsage(prompt_tokens=134, completion_tokens=64), content=\"Water turns into ice under 0°C because the kinetic energy of water molecules decreases, causing them to move less and form a structured, crystalline lattice. This phase change is due to the hydrogen bonds between water molecules becoming more stable at lower temperatures. However, why do you think some substances don't freeze at 0°C?\", type='TextMessage'), TextMessage(source='student_agent', models_usage=RequestUsage(prompt_tokens=197, completion_tokens=77), content=\"Some substances don't freeze at 0°C because their molecular structures and intermolecular forces differ from water. For example, alcohol has weaker hydrogen bonds and a lower freezing point. Is it correct to say that if I have a glass of pure water at -5°C, it will turn into ice because the temperature is below 0°C, allowing the water molecules to form a solid structure?\", type='TextMessage'), TextMessage(source='teacher_agent', models_usage=RequestUsage(prompt_tokens=289, completion_tokens=57), content='Not necessarily. Pure water can remain liquid below 0°C in a state called supercooling, especially if undisturbed and free of impurities. It requires a nucleation point or disturbance to initiate freezing. What factors do you think might influence the likelihood of supercooling occurring?', type='TextMessage'), TextMessage(source='student_agent', models_usage=RequestUsage(prompt_tokens=345, completion_tokens=60), content='Factors influencing supercooling include the purity of the water, the presence of impurities or nucleation sites, and the level of disturbance. For instance, if I have a bottle of pure water at -5°C and shake it, the disturbance could trigger the water to freeze. Is this understanding correct?', type='TextMessage'), TextMessage(source='teacher_agent', models_usage=RequestUsage(prompt_tokens=420, completion_tokens=43), content=\"Yes, that's correct. Disturbance or impurities can indeed trigger freezing in supercooled water. Your understanding of supercooling and its influencing factors is accurate. TEACHER IS WILLING TO TERMINATE.\", type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The group chat will alternate between the assistant and the code executor.\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "group_chat = RoundRobinGroupChat([teacher_agent, student_agent], termination_condition=termination)\n",
    "\n",
    "stream = group_chat.run_stream(task=\"why does the water turns into ice under 0 celsius degrees?\")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc66af-7e9f-4a22-a162-c77b1049b563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e7071-32e8-43ad-8055-6f1a65a95586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8516f01-fbe3-4302-a38a-426e3bb0b391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e83e16-8e81-4cd5-bd0f-fdfb7969bdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfc0dd-abe0-49c2-a640-beda20ee3c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee55e6-2312-4675-abd6-f8348dd34e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531b6a9-bfcb-4b1e-a0a3-94a4f761cbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34046f-6dbb-443b-b22d-a760c4243ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a14278-66ad-400a-a750-b0cd22221b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7942766e-1a0b-4bbb-9357-864bb2c007a3",
   "metadata": {},
   "source": [
    "# Create AI Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9abb62-b855-402f-9e22-583ffe6bf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import BingGroundingTool # <<<<<<<<<<<<<<< SPECIFIC FOR BING SEARCH\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "project_client.scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762bfd5-4440-487e-a2d6-235bacb612b0",
   "metadata": {},
   "source": [
    "# Create the wrapper function for the BING AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43800ee-3651-4582-b20f-e61fe6095cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_ai_agent(query: str) -> str:\n",
    "    print(\"This is Bing for Azure AI Agent Service...\")\n",
    "    \n",
    "    # Retrieve the BING Connection already associated to the AI Foundry project\n",
    "    bing_connection = project_client.connections.get(connection_name=os.environ[\"BING_CONNECTION_NAME\"])\n",
    "    \n",
    "    # Build BingGroundingTool\n",
    "    bing = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "    # Create the Bing Agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"bing-agent\",\n",
    "        instructions=\"\"\"\n",
    "            You are a web search agent.\n",
    "            Your only tool is search_tool - use it to find information.\n",
    "            You make only one search call at a time.\n",
    "            Once you have the resutls, you never do any elaboration of the obtained results.\n",
    "            \"\"\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "    print(f\"Created BING agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a user message to the thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, \n",
    "        role=\"user\", \n",
    "        content=query, # \"What is the top news today\", \"Quali sono i programmi TV stasera?\"\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process assistant run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run\\\n",
    "        (thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}. Run id: {run.id}\")\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    \n",
    "    if run.status == 'completed':    \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        # get the most recent message from the assistant\n",
    "        last_msg = messages.get_last_text_message_by_sender(\"assistant\")\n",
    "\n",
    "    print(f\"Number of annotation(s): {len(last_msg.text.annotations)}\")\n",
    "\n",
    "    a = 0\n",
    "    for annotation in last_msg.text.annotations:\n",
    "        a += 1\n",
    "        print(f'- Annotation {a} of {len(last_msg.text.annotations)}.\\n  - Text: {annotation[\"text\"]}\\n  - URL: {annotation[\"url_citation\"][\"url\"]}')\n",
    "        \n",
    "    print (f\"Deleting agent {agent.id}...\")\n",
    "    project_client.agents.delete_agent(agent.id)    \n",
    "    \n",
    "    if last_msg:\n",
    "        print(f\"\\nLast Message: {last_msg.text.value}\")\n",
    "\n",
    "    return last_msg.text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc7898-7381-4bf7-93c2-73501da52206",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_result = web_ai_agent(\"What is the top news today?\")\n",
    "web_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a3f42-f8a5-45e7-a668-8d02ec4356b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_search_agent.run(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ace3e-779f-4265-a7d9-bcb20abb62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "bing_search_agent = AssistantAgent(\n",
    "    name=\"bing_search_agent\",\n",
    "    model_client=model_client,\n",
    "    # tools=[web_ai_agent],\n",
    "    system_message=\"You are a search expert, help me use tools to find relevant knowledge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27527f-eb8c-40a1-827e-763258f547a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e28f75-580b-44b3-9577-d9f820e92625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a92cc-b1c0-4721-901c-0a47c1bed7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdf36fe-7b6c-4c90-adfe-18a7d3c7f438",
   "metadata": {},
   "source": [
    "# Create AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f633c-5707-43e7-919c-aeb0728b3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent creation\n",
    "# Notices that FileSearchTool as tool and tool_resources must be added or the assistant unable to search the file\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=model_name,\n",
    "    name=\"bing-agent\",\n",
    "    instructions=\"You are helpful assistant\",\n",
    "    tools=bing.definitions,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"}\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {agent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71597a-eec6-47dd-87c7-e0f0629a18bc",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f80125-1252-4060-bdf5-3b52acc42a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread: {thread}\\n\")\n",
    "\n",
    "# Add a user message to the thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\", \n",
    "    content=\"What is the top news today?\", # \"What is the top news today\", \"Quali sono i programmi TV stasera?\"\n",
    ")\n",
    "print(f\"Created message: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162865aa-4557-4038-95cc-6740b70c4d81",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604f495-2519-42a7-a19a-026538cf2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create and process assistant run in thread with tools\n",
    "run = project_client.agents.create_and_process_run\\\n",
    "    (thread_id=thread.id, assistant_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}.\\n\\nRun: {run}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d7f25-29a4-41d7-8b56-a2727266d094",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd778151-0cbb-4216-8de9-e4dee771d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import MessageTextContent, MessageImageFileContent\n",
    "\n",
    "if run.status == 'completed':    \n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    messages_nr = len(messages.data)\n",
    "    print(f\"Here are the {messages_nr} messages, starting with the most recent one:\\n\")\n",
    "    i=0\n",
    "    for m in messages.data:\n",
    "        j = 0\n",
    "        i += 1\n",
    "        print(f\"\\n===== MESSAGE {messages_nr-i+1} =====\")\n",
    "        for c in m.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nCONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "            elif (type(c) is MessageTextContent):\n",
    "                print(f\"\\nCONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a.text}\\n\")\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3222fb-0f69-43ec-8762-65cc8242df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last message from the sender\n",
    "last_msg = messages.get_last_text_message_by_sender(\"assistant\")\n",
    "if last_msg:\n",
    "    print(f\"Last Message: {last_msg.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1af78b-d00b-4e9f-a449-f007fe1ecc2f",
   "metadata": {},
   "source": [
    "# Print annotations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a46d95-6368-428e-8335-761e3661e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of annotation(s): {len(last_msg.text.annotations)}\")\n",
    "\n",
    "for annotation in last_msg.text.annotations:\n",
    "    print(annotation[\"text\"], annotation[\"url_citation\"][\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4020af-2bd6-4550-a2f5-c19a48daa95c",
   "metadata": {},
   "source": [
    "# Run Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd551092-22cb-465c-baa3-ff58823fbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "run_steps_data = run_steps['data']\n",
    "print(f\"Last run step detail: {run_steps_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a57be-292d-4008-b3de-68c9878b2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "\n",
    "print(f\"Nr of run step(s): {len(run_steps)}\\n\")\n",
    "i=0\n",
    "for rs in run_steps[\"data\"]:\n",
    "    i += 1\n",
    "    print(f\"Run step {i}: {rs}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ec759-c053-4ab7-81aa-15cfa4961468",
   "metadata": {},
   "source": [
    "# START Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48399858-16e3-4b7c-a13a-aa3ed8320539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all agents\n",
    "\n",
    "print(f\"{len(project_client.agents.list_agents()['data'])} agent(s) will now be deleted\")\n",
    "\n",
    "i=0\n",
    "for pca in project_client.agents.list_agents()['data']:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(pca.id)\n",
    "    print(f\"\\n{i} - Agent {pca.name} has been deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc2b04-a0b3-45ee-9066-4306e16511f9",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
