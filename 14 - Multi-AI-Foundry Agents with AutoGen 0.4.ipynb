{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aff6e2d-97b4-441c-b548-2557bafae055",
   "metadata": {},
   "source": [
    "# [Multi-AI-Foundry Agents with AutoGen 0.4](https://github.com/kinfey/MultiAIAgent/blob/main/04.AzureAIAgentWithAutoGen02.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc713e0d-8aba-48bd-8217-30b9b558a7d6",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d9cc9d-cbef-4b35-a4a3-84802dd4ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Connection String: <...mai04-rg;mmai-hub04-prj01-fvye>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO) # Configure logging \n",
    "\n",
    "load_dotenv(\"./../config/credentials_my.env\")\n",
    "env_or_file='./../config/models_list.json'\n",
    "filter_dict = {\n",
    "    'endpoint': 'https://mmai-hub04-ai-servicesfvye.openai.azure.com/',\n",
    "    'deployment': 'gpt-4o-2024-08-06'\n",
    "}\n",
    "\n",
    "model_name =  filter_dict[\"deployment\"] # https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview#setup\n",
    "project_connection_string = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "print(f'Project Connection String: <...{project_connection_string[-30:]}>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ac1a4-739b-40fb-bec2-1044fc23332b",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Inspired by [Migration Guide for v0.2 to v0.4](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6c2a43-6253-4947-b6f8-468c8c9c4ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen Configuration: https://mmai-hub04-ai-servicesfvye.openai.azure.com/, gpt-4o-2024-08-06, 2024-10-01-preview, ...\n"
     ]
    }
   ],
   "source": [
    "def config_list_from_json(env_or_file, filter_dict):\n",
    "    import json\n",
    "    with open(env_or_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    filtered_data = [\n",
    "        item for item in data\n",
    "        if item.get('endpoint') == filter_dict.get('endpoint') and item.get('deployment') == filter_dict.get('deployment')\n",
    "    ]    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "autogen_config = config_list_from_json(env_or_file, filter_dict)[0] # we take the first combination of model and endpoint\n",
    "\n",
    "# beaware NOT to show the API KEY\n",
    "print(f'AutoGen Configuration: {autogen_config[\"endpoint\"]}, {autogen_config[\"deployment\"]}, {autogen_config[\"api_version\"]}, ...') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213e1a7-2196-4820-a6c9-5f9417e5de3f",
   "metadata": {},
   "source": [
    "# Model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef361c73-8f0f-4049-a806-e891ba8e8dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'temperature': 0.1,\n",
       " 'model': 'gpt-4o',\n",
       " 'azure_endpoint': 'https://mmai-hub04-ai-servicesfvye.openai.azure.com/',\n",
       " 'azure_deployment': 'gpt-4o-2024-08-06',\n",
       " 'api_version': '2024-10-01-preview'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=autogen_config[\"endpoint\"],\n",
    "    api_key=autogen_config[\"api_key\"],\n",
    "    model = autogen_config[\"model\"],\n",
    "    azure_deployment = autogen_config[\"deployment\"],\n",
    "    api_version=autogen_config[\"api_version\"],\n",
    "    seed = 42,\n",
    "    temperature = 0.1,\n",
    ")\n",
    "\n",
    "# Create a copy of the dictionary  \n",
    "data_to_print = model_client.dump_component().config.copy()\n",
    "\n",
    "# Remove the 'api_key' from the copy  \n",
    "del data_to_print['api_key']  \n",
    "  \n",
    "data_to_print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942766e-1a0b-4bbb-9357-864bb2c007a3",
   "metadata": {},
   "source": [
    "# Create AI Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9abb62-b855-402f-9e22-583ffe6bf8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subscription_id': 'eca2eddb-0f0c-4351-a634-52751499eeea',\n",
       " 'resource_group_name': 'mmai04-rg',\n",
       " 'project_name': 'mmai-hub04-prj01-fvye'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "project_client.scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5a46a-b377-4624-b104-abd5b937e3d6",
   "metadata": {},
   "source": [
    "# Create wrapper functions for AI Foundry Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762bfd5-4440-487e-a2d6-235bacb612b0",
   "metadata": {},
   "source": [
    "## Wrapper function for the BING AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43800ee-3651-4582-b20f-e61fe6095cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def web_ai_agent(query: str) -> str:\n",
    "    from azure.ai.projects.models import BingGroundingTool # <<<<<<<<<<<<<<< SPECIFIC FOR BING SEARCH    \n",
    "    \n",
    "    print(\"This is Bing for Azure AI Agent Service...\")\n",
    "    \n",
    "    # Retrieve the BING Connection already associated to the AI Foundry project\n",
    "    bing_connection = project_client.connections.get(connection_name=os.environ[\"BING_CONNECTION_NAME\"])\n",
    "    \n",
    "    # Build BingGroundingTool\n",
    "    bing = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "    # Create the Bing Agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"bing-agent\",\n",
    "        instructions=\"\"\"\n",
    "            You are a web search agent.\n",
    "            Your only tool is search_tool - use it to find information.\n",
    "            You make only one search call at a time.\n",
    "            Once you have the results, you never do any elaboration of the obtained results.\n",
    "            \"\"\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "    print(f\"Created BING agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a user message to the thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, \n",
    "        role=\"user\", \n",
    "        content=query, # \"What is the top news today\", \"Quali sono i programmi TV stasera?\"\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process assistant run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run\\\n",
    "        (thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}. Run id: {run.id}\")\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "        result = run.last_error\n",
    "    elif run.status == 'completed':    \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        # get the most recent message from the assistant\n",
    "        last_msg = messages.get_last_text_message_by_sender(\"assistant\")        \n",
    "        if last_msg:\n",
    "            result = last_msg.text.value\n",
    "            print(f\"\\nLast Message: {result}\")\n",
    "\n",
    "        # Annotations\n",
    "        print(f\"Number of annotation(s): {len(last_msg.text.annotations)}\")    \n",
    "        a = 0\n",
    "        for annotation in last_msg.text.annotations:\n",
    "            a += 1\n",
    "            print(f'- Annotation {a} of {len(last_msg.text.annotations)}.\\n  - Text: {annotation[\"text\"]}\\n  - URL: {annotation[\"url_citation\"][\"url\"]}')\n",
    "    \n",
    "    print (f\"Deleting agent {agent.id}...\")\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbc7898-7381-4bf7-93c2-73501da52206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_OMHbCx6qfhg9fQ0QtnHVfcjr\n",
      "Created thread, ID: thread_g17LRNoYdtC1HFlRoqxwOj0p\n",
      "Created message, ID: msg_dOWM9Qd3Ss5rCTZvsAK5KqoU\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_19zV4ep6kkBLjWRpJusWjcCC\n",
      "\n",
      "Last Message: Today's top news includes the upcoming inauguration of Donald Trump as President of the United States. The inauguration ceremony is scheduled for today, January 20, 2025【6†source】【9†source】. In global news, the ruling Party of the Revolution in Tanzania has endorsed candidates for the 2025 presidential elections【4†source】.\n",
      "Number of annotation(s): 3\n",
      "- Annotation 1 of 3.\n",
      "  - Text: 【6†source】\n",
      "  - URL: https://wtop.com/podcast/top-news-from-wtop/monday-january-20-2025-1259-am/\n",
      "- Annotation 2 of 3.\n",
      "  - Text: 【9†source】\n",
      "  - URL: https://www.fox5dc.com/news/trump-transition-inauguration-day-2025-schedule\n",
      "- Annotation 3 of 3.\n",
      "  - Text: 【4†source】\n",
      "  - URL: https://news-pravda.com/world/2025/01/20/990388.html\n",
      "Deleting agent asst_OMHbCx6qfhg9fQ0QtnHVfcjr...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Today's top news includes the upcoming inauguration of Donald Trump as President of the United States. The inauguration ceremony is scheduled for today, January 20, 2025【6†source】【9†source】. In global news, the ruling Party of the Revolution in Tanzania has endorsed candidates for the 2025 presidential elections【4†source】.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the wrapper function for the BING Agent\n",
    "\n",
    "web_result = await web_ai_agent(\"What is the top news today?\")\n",
    "web_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea55ed-a84c-4033-87d7-7e1820810b3f",
   "metadata": {},
   "source": [
    "## Wrapper function for the CodeInterpreter AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f514c8-9500-4612-9602-428fa08a2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def codeinterpreter_ai_agent(action: str) -> str:\n",
    "    from azure.ai.projects.models import CodeInterpreterTool # <<<<<<<<<<<<<<< SPECIFIC FOR CODE INTERPRETER\n",
    "    from azure.ai.projects.models import MessageTextContent, MessageImageFileContent\n",
    "    \n",
    "    print(\"This is CodeInterpreter for Azure AI Agent Service...\")\n",
    "    \n",
    "    # Build CodeInterpreterTool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "    # Create the Code Interpreter Agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"codeinterpreter_agent\",\n",
    "        instructions=\"\"\"\n",
    "            You are a helpful agent.\n",
    "            \"\"\",\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "        )\n",
    "    print(f\"Created CODE INTERPRETER agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a user message to the thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, \n",
    "        role=\"user\", \n",
    "        content=action, # How much is seventythree elevated to the power of minus 3.5?\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process assistant run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run\\\n",
    "        (thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}. Run id: {run.id}\")\n",
    "    \n",
    "    if run.status == 'completed':    \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        messages_nr = len(messages.data)\n",
    "        print(f\"Here is the content of the last message:\")\n",
    "        j = 0\n",
    "        for c in messages.data[0].content:\n",
    "            j += 1\n",
    "            if (type(c) is MessageImageFileContent):\n",
    "                print(f\"CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "            elif (type(c) is MessageTextContent):\n",
    "                result = c.text.value\n",
    "                print(f\"CONTENT {j} (MessageTextContent) --> Text: {result}\")\n",
    "                for a in c.text.annotations:\n",
    "                    print(f\">>> Annotation in MessageTextContent {j}: {a.text}\")    \n",
    "        \n",
    "        print (f\"\\nNr. of file path annotations: {len(messages.file_path_annotations)}\")\n",
    "        i=0\n",
    "        for file_path_annotation in messages.file_path_annotations:\n",
    "            i += 1\n",
    "            print(f\"{i} - File annotation paths: {file_path_annotation}\")\n",
    "            file_name = file_path_annotation.text.split('/')[-1]\n",
    "            project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "            print(f\"File annoation {i} saved as file to: {os.getcwd()}\\\\{file_name}\")\n",
    "    \n",
    "        # Images\n",
    "        print (f\"Nr. of image contents: {len(messages.image_contents)}\\n\")\n",
    "        \n",
    "        i=0\n",
    "        # Generate an image file for the bar chart\n",
    "        for image_content in messages.image_contents:\n",
    "            i += 1\n",
    "            print(f\"{i} - Image content: {image_content}\")\n",
    "            file_name = f\"{image_content.image_file.file_id}_image_content.png\"\n",
    "            project_client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "            print(f\"Image content {i} file to: {os.getcwd()}\\\\{file_name}\")\n",
    "            \n",
    "    elif run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Sorry, I can't proceed because the run status is {run.status}: {run.last_error}\")\n",
    "        result = run.last_error\n",
    "\n",
    "    print (f\"Deleting agent {agent.id}...\")\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36292004-7211-4311-a870-6e7097263b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is CodeInterpreter for Azure AI Agent Service...\n",
      "Created CODE INTERPRETER agent, ID: asst_SbaCywncjtKZutcCIQX7ysON\n",
      "Created thread, ID: thread_3oIwael0gnXDGoKPUljpaObw\n",
      "Created message, ID: msg_sII3ZdnvP0xFzsYfpAsTjeh3\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_SbEHRj9GZ861zDaIJMFbFmJt\n",
      "Here is the content of the last message:\n",
      "CONTENT 1 (MessageTextContent) --> Text: I've created the bar chart for the operating profits and saved it as an image file. You can download it using the link below:\n",
      "\n",
      "[Download the chart](sandbox:/mnt/data/operating_profit_chart.png)\n",
      ">>> Annotation in MessageTextContent 1: sandbox:/mnt/data/operating_profit_chart.png\n",
      "\n",
      "Nr. of file path annotations: 1\n",
      "1 - File annotation paths: {'type': 'file_path', 'text': 'sandbox:/mnt/data/operating_profit_chart.png', 'start_index': 148, 'end_index': 192, 'file_path': {'file_id': 'assistant-6AGtQLYDKRQ5W8jTd8oO0NwX'}}\n",
      "File annoation 1 saved as file to: E:\\Users\\mauromi\\source\\git_repos\\aaas\\operating_profit_chart.png\n",
      "Nr. of image contents: 0\n",
      "\n",
      "Deleting agent asst_SbaCywncjtKZutcCIQX7ysON...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I've created the bar chart for the operating profits and saved it as an image file. You can download it using the link below:\\n\\n[Download the chart](sandbox:/mnt/data/operating_profit_chart.png)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the wrapper function for the Code Interpreter Agent\n",
    "\n",
    "# How much is seventythree elevated to the power of minus 3.5?\n",
    "codeinterpreter_result = await codeinterpreter_ai_agent(\"\"\"\n",
    "    Could you please create a bar chart for the operating profit using \n",
    "    the following data and provide the file to me? \n",
    "    Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, \n",
    "    Company D: $1.8 million\n",
    "    \"\"\")\n",
    "\n",
    "codeinterpreter_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767af41-bc66-4331-8eff-79e895bf6fcd",
   "metadata": {},
   "source": [
    "# AUTOGEN!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a6eba-18ab-4bb1-8ecd-4c863c792a0b",
   "metadata": {},
   "source": [
    "# Define the corresponding AutoGen Assistant Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b27527f-eb8c-40a1-827e-763258f547a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT AGENT 1: BING SEARCH\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "bingsearch_assistant = AssistantAgent(\n",
    "    name=\"bingsearch_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_ai_agent],\n",
    "    system_message=\"\"\"\n",
    "    You are a search expert, help me use tools to find relevant knowledge.\n",
    "    Pass your result to the next agent.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caba181e-b37c-4f34-8e6f-82c6f0dd2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT AGENT 2: CODE INTERPRETER\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "codeinterpreter_assistant = AssistantAgent(\n",
    "    name=\"codeinterpreter_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[codeinterpreter_ai_agent],\n",
    "    system_message='''\n",
    "    You are a clever assistant that is able to \"DO THINGS\" by running python code **without asking any confirmation**.\n",
    "    If you generate any files, please **ALSO** then download them locally and tell me their path.\n",
    "    Pass your result to the next agent.\n",
    "    ''',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8ace3e-779f-4265-a7d9-bcb20abb62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT AGENT 3: ITALIAN TRANSLATOR\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "italiantranslator_assistant = AssistantAgent(\n",
    "    name=\"italiantranslator_assistant\",\n",
    "    model_client=model_client,\n",
    "    # NO TOOLS\n",
    "    system_message=\"\"\"\n",
    "    You are an expert translator to Italian. You always translate every text to Italian.\n",
    "    As soon as the translation is done, close the conversation saying 'ITALIAN TRANSLATOR IS WILLING TO TERMINATE'.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bee34-e9ac-4065-9787-0b83df40e20c",
   "metadata": {},
   "source": [
    "# Termination Condition\n",
    "It's a combination of text termination and max message termination, either of which will cause the chat to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739873f8-dc0c-4623-9a7b-c7c343f4c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fbc9d-37cb-45ce-9be5-3cb0c9903497",
   "metadata": {},
   "source": [
    "# Autogen Group Chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7e33f-d815-472d-924c-d9953703ac2d",
   "metadata": {},
   "source": [
    "## Peer-to-Peer Round Robin Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192c1a33-aba8-4eef-9908-f061bbf9052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "\n",
      "    First, find the expected min and max temperature tomorrow in Rome, Moscow and Sydney. \n",
      "    Then, create the image of a bar chart for the two temperatures of tomorrow.\n",
      "    Then, download the file on my local PC.\n",
      "    Translate the answer to Italian.\n",
      "    \n",
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_VlJUXqRDYEJEp0aYDCwbIsVu\n",
      "Created thread, ID: thread_hyGW6kkieGqhXxay6eL5PoUt\n",
      "Created message, ID: msg_hlhOxNthxkKeU0EVmvmP9gCb\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_LTmAlSWOXLDA9di0f23yaecm\n",
      "\n",
      "Last Message: The expected minimum temperature in Rome tomorrow, January 21, 2025, is 6°C, and the maximum temperature is 12°C【5†source】.\n",
      "Number of annotation(s): 1\n",
      "- Annotation 1 of 1.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://www.meteoprog.com/weather/Rome/month/january/\n",
      "Deleting agent asst_VlJUXqRDYEJEp0aYDCwbIsVu...\n",
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_ErqETu3lm56DpNFs8ZHfAt44\n",
      "Created thread, ID: thread_rQEijuWmZ0UxP13wsKzAHJwD\n",
      "Created message, ID: msg_I0tTRGdjHCpwMugX1uhz8sHj\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_dsMWEYG2fN21D0HZJOvdLaKD\n",
      "\n",
      "Last Message: The expected minimum and maximum temperatures in Moscow for tomorrow, January 21, 2025, are -2°C and 1°C, respectively【5†source】.\n",
      "Number of annotation(s): 1\n",
      "- Annotation 1 of 1.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://www.timeanddate.com/weather/russia/moscow/hourly\n",
      "Deleting agent asst_ErqETu3lm56DpNFs8ZHfAt44...\n",
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_qjkp59xDY6qDYuonlirZBHMA\n",
      "Created thread, ID: thread_KVXrEY3nxMpEmuQUd1uC6sCC\n",
      "Created message, ID: msg_jpybmqJeNUCZjzHhKCS02Fd0\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_Ri1Jvf0msNpvQqM4htORiwtB\n",
      "\n",
      "Last Message: The expected minimum and maximum temperatures in Sydney for January 21, 2025, are 21°C and 26°C respectively【5†source】.\n",
      "Number of annotation(s): 1\n",
      "- Annotation 1 of 1.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://weather.com/en-AU/weather/monthly/l/98ef17e6662508c0af6d8bd04adacecde842fb533434fcd2c046730675fba371\n",
      "Deleting agent asst_qjkp59xDY6qDYuonlirZBHMA...\n",
      "---------- bingsearch_assistant ----------\n",
      "[FunctionCall(id='call_EdzzI4FVAIzPQAA654X6HeCh', arguments='{\"query\": \"expected minimum and maximum temperature in Rome tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_QTZDk41DXGdKkNwVYV8CNHrl', arguments='{\"query\": \"expected minimum and maximum temperature in Moscow tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_Xibte5INFGFU1oR8zj488WPu', arguments='{\"query\": \"expected minimum and maximum temperature in Sydney tomorrow\"}', name='web_ai_agent')]\n",
      "---------- bingsearch_assistant ----------\n",
      "[FunctionExecutionResult(content='The expected minimum temperature in Rome tomorrow, January 21, 2025, is 6°C, and the maximum temperature is 12°C【5†source】.', call_id='call_EdzzI4FVAIzPQAA654X6HeCh'), FunctionExecutionResult(content='The expected minimum and maximum temperatures in Moscow for tomorrow, January 21, 2025, are -2°C and 1°C, respectively【5†source】.', call_id='call_QTZDk41DXGdKkNwVYV8CNHrl'), FunctionExecutionResult(content='The expected minimum and maximum temperatures in Sydney for January 21, 2025, are 21°C and 26°C respectively【5†source】.', call_id='call_Xibte5INFGFU1oR8zj488WPu')]\n",
      "---------- bingsearch_assistant ----------\n",
      "The expected minimum temperature in Rome tomorrow, January 21, 2025, is 6°C, and the maximum temperature is 12°C【5†source】.\n",
      "The expected minimum and maximum temperatures in Moscow for tomorrow, January 21, 2025, are -2°C and 1°C, respectively【5†source】.\n",
      "The expected minimum and maximum temperatures in Sydney for January 21, 2025, are 21°C and 26°C respectively【5†source】.\n",
      "This is CodeInterpreter for Azure AI Agent Service...\n",
      "Created CODE INTERPRETER agent, ID: asst_oY2R8iHqmSI3cqg3Hct0yiJ8\n",
      "Created thread, ID: thread_87z3gvJ7cfV9EQbwAhXUxu0P\n",
      "Created message, ID: msg_SfxjQ3wslAkInpPbcp5xdeF0\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_R4tjSfGSwXKZ2mz9w80dJsHq\n",
      "Here is the content of the last message:\n",
      "CONTENT 1 (MessageTextContent) --> Text: The bar chart comparing the minimum and maximum temperatures for the cities of Rome, Moscow, and Sydney has been created and saved as \"temperature_chart.png\". You can download it using the link below:\n",
      "\n",
      "[Download the temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)\n",
      "\n",
      "Nr. of file path annotations: 0\n",
      "Nr. of image contents: 0\n",
      "\n",
      "Deleting agent asst_oY2R8iHqmSI3cqg3Hct0yiJ8...\n",
      "---------- codeinterpreter_assistant ----------\n",
      "[FunctionCall(id='call_n9oyn7aYcw9KlHEVmwk6MmmE', arguments='{\"action\":\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the temperatures\\\\ncities = [\\'Rome\\', \\'Moscow\\', \\'Sydney\\']\\\\nmin_temps = [6, -2, 21]\\\\nmax_temps = [12, 1, 26]\\\\n\\\\n# Create a bar chart\\\\nx = range(len(cities))  # the label locations\\\\nwidth = 0.35  # the width of the bars\\\\n\\\\nfig, ax = plt.subplots()\\\\nrects1 = ax.bar(x, min_temps, width, label=\\'Min Temp\\')\\\\nrects2 = ax.bar([p + width for p in x], max_temps, width, label=\\'Max Temp\\')\\\\n\\\\n# Add some text for labels, title and custom x-axis tick labels, etc.\\\\nax.set_ylabel(\\'Temperature (°C)\\')\\\\nax.set_title(\\'Min and Max Temperatures for Tomorrow\\')\\\\nax.set_xticks([p + width/2 for p in x])\\\\nax.set_xticklabels(cities)\\\\nax.legend()\\\\n\\\\n# Save the figure\\\\nplt.savefig(\\'/mnt/data/temperature_chart.png\\')\\\\nplt.show()\"}', name='codeinterpreter_ai_agent')]\n",
      "---------- codeinterpreter_assistant ----------\n",
      "[FunctionExecutionResult(content='The bar chart comparing the minimum and maximum temperatures for the cities of Rome, Moscow, and Sydney has been created and saved as \"temperature_chart.png\". You can download it using the link below:\\n\\n[Download the temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)', call_id='call_n9oyn7aYcw9KlHEVmwk6MmmE')]\n",
      "---------- codeinterpreter_assistant ----------\n",
      "The bar chart comparing the minimum and maximum temperatures for the cities of Rome, Moscow, and Sydney has been created and saved as \"temperature_chart.png\". You can download it using the link below:\n",
      "\n",
      "[Download the temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)\n",
      "---------- italiantranslator_assistant ----------\n",
      "Le temperature minime e massime previste per domani sono le seguenti:\n",
      "\n",
      "- Roma: minima 6°C, massima 12°C\n",
      "- Mosca: minima -2°C, massima 1°C\n",
      "- Sydney: minima 21°C, massima 26°C\n",
      "\n",
      "L'immagine del grafico a barre che confronta le temperature minime e massime per le città di Roma, Mosca e Sydney è stata creata e salvata come \"temperature_chart.png\". Puoi scaricarla utilizzando il link qui sotto:\n",
      "\n",
      "[Scarica il file temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)\n",
      "\n",
      "ITALIAN TRANSLATOR IS WILLING TO TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='\\n    First, find the expected min and max temperature tomorrow in Rome, Moscow and Sydney. \\n    Then, create the image of a bar chart for the two temperatures of tomorrow.\\n    Then, download the file on my local PC.\\n    Translate the answer to Italian.\\n    ', type='TextMessage'), ToolCallRequestEvent(source='bingsearch_assistant', models_usage=RequestUsage(prompt_tokens=128, completion_tokens=82), content=[FunctionCall(id='call_EdzzI4FVAIzPQAA654X6HeCh', arguments='{\"query\": \"expected minimum and maximum temperature in Rome tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_QTZDk41DXGdKkNwVYV8CNHrl', arguments='{\"query\": \"expected minimum and maximum temperature in Moscow tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_Xibte5INFGFU1oR8zj488WPu', arguments='{\"query\": \"expected minimum and maximum temperature in Sydney tomorrow\"}', name='web_ai_agent')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='bingsearch_assistant', models_usage=None, content=[FunctionExecutionResult(content='The expected minimum temperature in Rome tomorrow, January 21, 2025, is 6°C, and the maximum temperature is 12°C【5†source】.', call_id='call_EdzzI4FVAIzPQAA654X6HeCh'), FunctionExecutionResult(content='The expected minimum and maximum temperatures in Moscow for tomorrow, January 21, 2025, are -2°C and 1°C, respectively【5†source】.', call_id='call_QTZDk41DXGdKkNwVYV8CNHrl'), FunctionExecutionResult(content='The expected minimum and maximum temperatures in Sydney for January 21, 2025, are 21°C and 26°C respectively【5†source】.', call_id='call_Xibte5INFGFU1oR8zj488WPu')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='bingsearch_assistant', models_usage=None, content='The expected minimum temperature in Rome tomorrow, January 21, 2025, is 6°C, and the maximum temperature is 12°C【5†source】.\\nThe expected minimum and maximum temperatures in Moscow for tomorrow, January 21, 2025, are -2°C and 1°C, respectively【5†source】.\\nThe expected minimum and maximum temperatures in Sydney for January 21, 2025, are 21°C and 26°C respectively【5†source】.', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='codeinterpreter_assistant', models_usage=RequestUsage(prompt_tokens=273, completion_tokens=258), content=[FunctionCall(id='call_n9oyn7aYcw9KlHEVmwk6MmmE', arguments='{\"action\":\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the temperatures\\\\ncities = [\\'Rome\\', \\'Moscow\\', \\'Sydney\\']\\\\nmin_temps = [6, -2, 21]\\\\nmax_temps = [12, 1, 26]\\\\n\\\\n# Create a bar chart\\\\nx = range(len(cities))  # the label locations\\\\nwidth = 0.35  # the width of the bars\\\\n\\\\nfig, ax = plt.subplots()\\\\nrects1 = ax.bar(x, min_temps, width, label=\\'Min Temp\\')\\\\nrects2 = ax.bar([p + width for p in x], max_temps, width, label=\\'Max Temp\\')\\\\n\\\\n# Add some text for labels, title and custom x-axis tick labels, etc.\\\\nax.set_ylabel(\\'Temperature (°C)\\')\\\\nax.set_title(\\'Min and Max Temperatures for Tomorrow\\')\\\\nax.set_xticks([p + width/2 for p in x])\\\\nax.set_xticklabels(cities)\\\\nax.legend()\\\\n\\\\n# Save the figure\\\\nplt.savefig(\\'/mnt/data/temperature_chart.png\\')\\\\nplt.show()\"}', name='codeinterpreter_ai_agent')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='codeinterpreter_assistant', models_usage=None, content=[FunctionExecutionResult(content='The bar chart comparing the minimum and maximum temperatures for the cities of Rome, Moscow, and Sydney has been created and saved as \"temperature_chart.png\". You can download it using the link below:\\n\\n[Download the temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)', call_id='call_n9oyn7aYcw9KlHEVmwk6MmmE')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='codeinterpreter_assistant', models_usage=None, content='The bar chart comparing the minimum and maximum temperatures for the cities of Rome, Moscow, and Sydney has been created and saved as \"temperature_chart.png\". You can download it using the link below:\\n\\n[Download the temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)', type='ToolCallSummaryMessage'), TextMessage(source='italiantranslator_assistant', models_usage=RequestUsage(prompt_tokens=289, completion_tokens=142), content='Le temperature minime e massime previste per domani sono le seguenti:\\n\\n- Roma: minima 6°C, massima 12°C\\n- Mosca: minima -2°C, massima 1°C\\n- Sydney: minima 21°C, massima 26°C\\n\\nL\\'immagine del grafico a barre che confronta le temperature minime e massime per le città di Roma, Mosca e Sydney è stata creata e salvata come \"temperature_chart.png\". Puoi scaricarla utilizzando il link qui sotto:\\n\\n[Scarica il file temperature_chart.png](sandbox:/mnt/data/temperature_chart.png)\\n\\nITALIAN TRANSLATOR IS WILLING TO TERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The group chat will alternate between the assistant and the code executor.\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "group_chat = RoundRobinGroupChat([bingsearch_assistant, codeinterpreter_assistant, italiantranslator_assistant], termination_condition=termination)\n",
    "\n",
    "stream = group_chat.run_stream(task=\"\"\"\n",
    "    First, find the expected min and max temperature tomorrow in Rome, Moscow and Sydney. \n",
    "    Then, create the image of a bar chart for the two temperatures of tomorrow.\n",
    "    Then, download the file on my local PC.\n",
    "    Translate the answer to Italian.\n",
    "    \"\"\")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ec759-c053-4ab7-81aa-15cfa4961468",
   "metadata": {},
   "source": [
    "# START Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48399858-16e3-4b7c-a13a-aa3ed8320539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agent(s) will now be deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete all agents\n",
    "\n",
    "print(f\"{len(project_client.agents.list_agents()['data'])} agent(s) will now be deleted\")\n",
    "\n",
    "i=0\n",
    "for pca in project_client.agents.list_agents()['data']:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(pca.id)\n",
    "    print(f\"\\n{i} - Agent {pca.name} has been deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc2b04-a0b3-45ee-9066-4306e16511f9",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
