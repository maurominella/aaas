{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aff6e2d-97b4-441c-b548-2557bafae055",
   "metadata": {},
   "source": [
    "# [Multi-AI-Foundry Agents with AutoGen 0.4](https://github.com/kinfey/MultiAIAgent/blob/main/04.AzureAIAgentWithAutoGen02.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc713e0d-8aba-48bd-8217-30b9b558a7d6",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d9cc9d-cbef-4b35-a4a3-84802dd4ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Connection String: <...mai04-rg;mmai-hub04-prj01-fvye>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO) # Configure logging \n",
    "\n",
    "load_dotenv(\"./../config/credentials_my.env\")\n",
    "env_or_file='./../config/models_list.json'\n",
    "filter_dict = {\n",
    "    'endpoint': 'https://mmai-hub04-ai-servicesfvye.openai.azure.com/',\n",
    "    'deployment': 'gpt-4o-2024-08-06'\n",
    "}\n",
    "\n",
    "model_name =  filter_dict[\"deployment\"] # https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview#setup\n",
    "project_connection_string = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "print(f'Project Connection String: <...{project_connection_string[-30:]}>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ac1a4-739b-40fb-bec2-1044fc23332b",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Inspired by [Migration Guide for v0.2 to v0.4](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6c2a43-6253-4947-b6f8-468c8c9c4ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGen Configuration: https://mmai-hub04-ai-servicesfvye.openai.azure.com/, gpt-4o-2024-08-06, 2024-10-01-preview, ...\n"
     ]
    }
   ],
   "source": [
    "def config_list_from_json(env_or_file, filter_dict):\n",
    "    import json\n",
    "    with open(env_or_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    filtered_data = [\n",
    "        item for item in data\n",
    "        if item.get('endpoint') == filter_dict.get('endpoint') and item.get('deployment') == filter_dict.get('deployment')\n",
    "    ]    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "autogen_config = config_list_from_json(env_or_file, filter_dict)[0] # we take the first combination of model and endpoint\n",
    "\n",
    "# beaware NOT to show the API KEY\n",
    "print(f'AutoGen Configuration: {autogen_config[\"endpoint\"]}, {autogen_config[\"deployment\"]}, {autogen_config[\"api_version\"]}, ...') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213e1a7-2196-4820-a6c9-5f9417e5de3f",
   "metadata": {},
   "source": [
    "# Model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef361c73-8f0f-4049-a806-e891ba8e8dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'temperature': 0.1,\n",
       " 'model': 'gpt-4o',\n",
       " 'azure_endpoint': 'https://mmai-hub04-ai-servicesfvye.openai.azure.com/',\n",
       " 'azure_deployment': 'gpt-4o-2024-08-06',\n",
       " 'api_version': '2024-10-01-preview'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=autogen_config[\"endpoint\"],\n",
    "    api_key=autogen_config[\"api_key\"],\n",
    "    model = autogen_config[\"model\"],\n",
    "    azure_deployment = autogen_config[\"deployment\"],\n",
    "    api_version=autogen_config[\"api_version\"],\n",
    "    seed = 42,\n",
    "    temperature = 0.1,\n",
    ")\n",
    "\n",
    "# Create a copy of the dictionary  \n",
    "data_to_print = model_client.dump_component().config.copy()\n",
    "\n",
    "# Remove the 'api_key' from the copy  \n",
    "del data_to_print['api_key']  \n",
    "  \n",
    "data_to_print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942766e-1a0b-4bbb-9357-864bb2c007a3",
   "metadata": {},
   "source": [
    "# Create AI Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9abb62-b855-402f-9e22-583ffe6bf8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subscription_id': 'eca2eddb-0f0c-4351-a634-52751499eeea',\n",
       " 'resource_group_name': 'mmai04-rg',\n",
       " 'project_name': 'mmai-hub04-prj01-fvye'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "project_client.scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5a46a-b377-4624-b104-abd5b937e3d6",
   "metadata": {},
   "source": [
    "# Create wrapper functions for AI Foundry Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762bfd5-4440-487e-a2d6-235bacb612b0",
   "metadata": {},
   "source": [
    "## Wrapper function for the BING AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43800ee-3651-4582-b20f-e61fe6095cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def web_ai_agent(query: str) -> str:\n",
    "    from azure.ai.projects.models import BingGroundingTool # <<<<<<<<<<<<<<< SPECIFIC FOR BING SEARCH    \n",
    "    \n",
    "    print(\"This is Bing for Azure AI Agent Service...\")\n",
    "    \n",
    "    # Retrieve the BING Connection already associated to the AI Foundry project\n",
    "    bing_connection = project_client.connections.get(connection_name=os.environ[\"BING_CONNECTION_NAME\"])\n",
    "    \n",
    "    # Build BingGroundingTool\n",
    "    bing = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "    # Create the Bing Agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"bing-agent\",\n",
    "        instructions=\"\"\"\n",
    "            You are a web search agent.\n",
    "            Your only tool is search_tool - use it to find information.\n",
    "            You make only one search call at a time.\n",
    "            Once you have the results, you never do any elaboration of the obtained results.\n",
    "            \"\"\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "    print(f\"Created BING agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a user message to the thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, \n",
    "        role=\"user\", \n",
    "        content=query, # \"What is the top news today\", \"Quali sono i programmi TV stasera?\"\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process assistant run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run\\\n",
    "        (thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}. Run id: {run.id}\")\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "        result = run.last_error\n",
    "    elif run.status == 'completed':    \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        # get the most recent message from the assistant\n",
    "        last_msg = messages.get_last_text_message_by_sender(\"assistant\")        \n",
    "        if last_msg:\n",
    "            result = last_msg.text.value\n",
    "            print(f\"\\nLast Message: {result}\")\n",
    "\n",
    "        # Annotations\n",
    "        print(f\"Number of annotation(s): {len(last_msg.text.annotations)}\")    \n",
    "        a = 0\n",
    "        for annotation in last_msg.text.annotations:\n",
    "            a += 1\n",
    "            print(f'- Annotation {a} of {len(last_msg.text.annotations)}.\\n  - Text: {annotation[\"text\"]}\\n  - URL: {annotation[\"url_citation\"][\"url\"]}')\n",
    "    \n",
    "    print (f\"Deleting agent {agent.id}...\")\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbc7898-7381-4bf7-93c2-73501da52206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_2JLB16r9nZSQCgBNoY9Y2P10\n",
      "Created thread, ID: thread_511dWo2Qo7QWrkhL5iuRmwit\n",
      "Created message, ID: msg_BAAkr8j5raEFK3OewWnxWwv3\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_X9pbQAvQmtmsIDqNpSgY12c7\n",
      "\n",
      "Last Message: Today's top news includes updates on the US with Donald Trump preparing to sign over presidential duties, and major ongoing news such as wildfires in California. Additionally, today's events are notable as they coincide with both Martin Luther King Jr. Day and Inauguration Day【5†source】【7†source】【15†source】.\n",
      "Number of annotation(s): 3\n",
      "- Annotation 1 of 3.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://www.msn.com/en-in/politics/government/world-news-live-today-january-20-2025-donald-trump-to-sign-over-200-executive-orders-on-day-one-focusing-on-border-security-energy-and-living-costs/ar-AA1xtsJJ\n",
      "- Annotation 2 of 3.\n",
      "  - Text: 【7†source】\n",
      "  - URL: https://en.wikipedia.org/wiki/Portal:Current_events/January_2025\n",
      "- Annotation 3 of 3.\n",
      "  - Text: 【15†source】\n",
      "  - URL: https://www.today.com/life/holidays/when-is-inauguration-day-2025-rcna186435\n",
      "Deleting agent asst_2JLB16r9nZSQCgBNoY9Y2P10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Today's top news includes updates on the US with Donald Trump preparing to sign over presidential duties, and major ongoing news such as wildfires in California. Additionally, today's events are notable as they coincide with both Martin Luther King Jr. Day and Inauguration Day【5†source】【7†source】【15†source】.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the wrapper function for the BING Agent\n",
    "\n",
    "web_result = await web_ai_agent(\"What is the top news today?\")\n",
    "web_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea55ed-a84c-4033-87d7-7e1820810b3f",
   "metadata": {},
   "source": [
    "## Wrapper function for the CodeInterpreter AI Foundry Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f514c8-9500-4612-9602-428fa08a2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def codeinterpreter_ai_agent(action: str) -> str:\n",
    "    from azure.ai.projects.models import CodeInterpreterTool # <<<<<<<<<<<<<<< SPECIFIC FOR CODE INTERPRETER\n",
    "    from azure.ai.projects.models import MessageTextContent, MessageImageFileContent\n",
    "    \n",
    "    print(\"This is CodeInterpreter for Azure AI Agent Service...\")\n",
    "    \n",
    "    # Build CodeInterpreterTool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "    # Create the Code Interpreter Agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=\"codeinterpreter_agent\",\n",
    "        instructions=\"\"\"\n",
    "            You are a helpful agent.\n",
    "            \"\"\",\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "        )\n",
    "    print(f\"Created CODE INTERPRETER agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a user message to the thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, \n",
    "        role=\"user\", \n",
    "        content=action, # How much is seventythree elevated to the power of minus 3.5?\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process assistant run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run\\\n",
    "        (thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}. Run id: {run.id}\")\n",
    "    \n",
    "    if run.status == 'completed':    \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        messages_nr = len(messages.data)\n",
    "        print(f\"Here is the content of the last message:\")\n",
    "        j = 0\n",
    "        for c in messages.data[0].content:\n",
    "            j += 1\n",
    "            if (type(c) is MessageImageFileContent):\n",
    "                print(f\"CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "            elif (type(c) is MessageTextContent):\n",
    "                result = c.text.value\n",
    "                print(f\"CONTENT {j} (MessageTextContent) --> Text: {result}\")\n",
    "                for a in c.text.annotations:\n",
    "                    print(f\">>> Annotation in MessageTextContent {j}: {a.text}\")    \n",
    "        \n",
    "        print (f\"\\nNr. of file path annotations: {len(messages.file_path_annotations)}\")\n",
    "        i=0\n",
    "        for file_path_annotation in messages.file_path_annotations:\n",
    "            i += 1\n",
    "            print(f\"{i} - File annotation paths: {file_path_annotation}\")\n",
    "            file_name = file_path_annotation.text.split('/')[-1]\n",
    "            project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "            print(f\"File annoation {i} saved as file to: {os.getcwd()}\\\\{file_name}\")\n",
    "    \n",
    "        # Images\n",
    "        print (f\"Nr. of image contents: {len(messages.image_contents)}\\n\")\n",
    "        \n",
    "        i=0\n",
    "        # Generate an image file for the bar chart\n",
    "        for image_content in messages.image_contents:\n",
    "            i += 1\n",
    "            print(f\"{i} - Image content: {image_content}\")\n",
    "            file_name = f\"{image_content.image_file.file_id}_image_content.png\"\n",
    "            project_client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "            print(f\"Image content {i} file to: {os.getcwd()}\\\\{file_name}\")\n",
    "            \n",
    "    elif run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Sorry, I can't proceed because the run status is {run.status}: {run.last_error}\")\n",
    "        result = run.last_error\n",
    "\n",
    "    print (f\"Deleting agent {agent.id}...\")\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36292004-7211-4311-a870-6e7097263b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is CodeInterpreter for Azure AI Agent Service...\n",
      "Created CODE INTERPRETER agent, ID: asst_WAQYCbzSBEhxhGovvNsjwnRw\n",
      "Created thread, ID: thread_BfK6tiDTq9PbMh8gt5iQxgwY\n",
      "Created message, ID: msg_eThENCIYjxZhObn9640iEy44\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_XhMniR1FYeJn2fzcYYAtpFeC\n",
      "Here is the content of the last message:\n",
      "CONTENT 1 (MessageImageFileContent) --> image_file id: assistant-tG16RuYzauTePJ46n0SfZ6xN\n",
      "CONTENT 2 (MessageTextContent) --> Text: The bar chart for the operating profit has been created. You can download it using the link below:\n",
      "\n",
      "[Download Operating Profit Bar Chart](sandbox:/mnt/data/operating_profit_bar_chart.png)\n",
      ">>> Annotation in MessageTextContent 2: sandbox:/mnt/data/operating_profit_bar_chart.png\n",
      "\n",
      "Nr. of file path annotations: 1\n",
      "1 - File annotation paths: {'type': 'file_path', 'text': 'sandbox:/mnt/data/operating_profit_bar_chart.png', 'start_index': 138, 'end_index': 186, 'file_path': {'file_id': 'assistant-iEX9Yl5oK0mImEbvbNcRsXVd'}}\n",
      "File annoation 1 saved as file to: E:\\Users\\mauromi\\source\\git_repos\\aaas\\operating_profit_bar_chart.png\n",
      "Nr. of image contents: 1\n",
      "\n",
      "1 - Image content: {'type': 'image_file', 'image_file': {'file_id': 'assistant-tG16RuYzauTePJ46n0SfZ6xN'}}\n",
      "Image content 1 file to: E:\\Users\\mauromi\\source\\git_repos\\aaas\\assistant-tG16RuYzauTePJ46n0SfZ6xN_image_content.png\n",
      "Deleting agent asst_WAQYCbzSBEhxhGovvNsjwnRw...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The bar chart for the operating profit has been created. You can download it using the link below:\\n\\n[Download Operating Profit Bar Chart](sandbox:/mnt/data/operating_profit_bar_chart.png)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the wrapper function for the Code Interpreter Agent\n",
    "\n",
    "# How much is seventythree elevated to the power of minus 3.5?\n",
    "codeinterpreter_result = await codeinterpreter_ai_agent(\"\"\"\n",
    "    Could you please create a bar chart for the operating profit using \n",
    "    the following data and provide the file to me? \n",
    "    Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, \n",
    "    Company D: $1.8 million\n",
    "    \"\"\")\n",
    "\n",
    "codeinterpreter_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767af41-bc66-4331-8eff-79e895bf6fcd",
   "metadata": {},
   "source": [
    "# AUTOGEN!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a6eba-18ab-4bb1-8ecd-4c863c792a0b",
   "metadata": {},
   "source": [
    "# Define the corresponding AutoGen Assistant Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b27527f-eb8c-40a1-827e-763258f547a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT AGENT 1: BING SEARCH\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "bingsearch_assistant = AssistantAgent(\n",
    "    name=\"bingsearch_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_ai_agent],\n",
    "    system_message=\"\"\"\n",
    "    You are a search expert, help me use tools to find relevant knowledge.\n",
    "    Pass your result to the next agent.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caba181e-b37c-4f34-8e6f-82c6f0dd2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT AGENT 2: CODE INTERPRETER\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "codeinterpreter_assistant = AssistantAgent(\n",
    "    name=\"codeinterpreter_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[codeinterpreter_ai_agent],\n",
    "    system_message='''\n",
    "    You are a clever assistant that is able to \"DO THINGS\" by running python code **without asking any confirmation**.\n",
    "    If you generate any files, please **ALSO** then download them locally and tell me their path.\n",
    "    Pass your result to the next agent.\n",
    "    ''',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8ace3e-779f-4265-a7d9-bcb20abb62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSISTANT AGENT 3: ITALIAN TRANSLATOR\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "italiantranslator_assistant = AssistantAgent(\n",
    "    name=\"italiantranslator_assistant\",\n",
    "    model_client=model_client,\n",
    "    # NO TOOLS\n",
    "    system_message=\"\"\"\n",
    "    You are an expert translator to Italian. You always translate every text to Italian.\n",
    "    As soon as the translation is done, close the conversation saying 'ITALIAN TRANSLATOR IS WILLING TO TERMINATE'.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bee34-e9ac-4065-9787-0b83df40e20c",
   "metadata": {},
   "source": [
    "# Termination Condition\n",
    "It's a combination of text termination and max message termination, either of which will cause the chat to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739873f8-dc0c-4623-9a7b-c7c343f4c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fbc9d-37cb-45ce-9be5-3cb0c9903497",
   "metadata": {},
   "source": [
    "# Autogen Group Chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7e33f-d815-472d-924c-d9953703ac2d",
   "metadata": {},
   "source": [
    "## Peer-to-Peer Round Robin Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192c1a33-aba8-4eef-9908-f061bbf9052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "\n",
      "    First, find the expected min and max temperature tomorrow in Rome, Moscow and Sydney. \n",
      "    Then, create the image of a bar chart for the two temperatures of tomorrow.\n",
      "    Then, download the file on my local PC.\n",
      "    Translate the answer to Italian.\n",
      "    \n",
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_U1ckvojg0gZKKveikYBuMohN\n",
      "Created thread, ID: thread_M9eh5GXgEA11iHrtYLqmPctd\n",
      "Created message, ID: msg_oZObbxmMVW2WSXJfCBtWxp3e\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_4I6esvZFoceAbdv9iwV11P2V\n",
      "\n",
      "Last Message: The weather forecast for Rome on January 21, 2025, predicts a minimum temperature of 6°C and a maximum temperature of 12°C【5†source】.\n",
      "Number of annotation(s): 1\n",
      "- Annotation 1 of 1.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://www.meteoprog.com/weather/Rome/month/january/\n",
      "Deleting agent asst_U1ckvojg0gZKKveikYBuMohN...\n",
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_I15XMWfJQsTVKOQ1WgVTgI81\n",
      "Created thread, ID: thread_wDPdOcbIiCDgCMhwTtSPNpNo\n",
      "Created message, ID: msg_6kN6RJrpWHMBjU7TtlQI1KcH\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_1190BvTKN50q3sSHzv0yVo6P\n",
      "\n",
      "Last Message: In Moscow, on January 21, 2025, the expected minimum temperature is -2°C and the maximum temperature is 1°C【5†source】.\n",
      "Number of annotation(s): 1\n",
      "- Annotation 1 of 1.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://www.weather25.com/europe/russia?page=month&month=January\n",
      "Deleting agent asst_I15XMWfJQsTVKOQ1WgVTgI81...\n",
      "This is Bing for Azure AI Agent Service...\n",
      "Created BING agent, ID: asst_YaekF8FSleVzbWKhY2Mz58in\n",
      "Created thread, ID: thread_JTQ93jqiZ2RiOD2gVoCWS9Pp\n",
      "Created message, ID: msg_OzZIRBCpEE0zDRMEKFIxsw58\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_FoWEwrGjppZNE39Ivv0h2C6x\n",
      "\n",
      "Last Message: The expected minimum and maximum temperatures in Sydney tomorrow, January 21, 2025, are approximately 21°C and 26°C【5†source】.\n",
      "Number of annotation(s): 1\n",
      "- Annotation 1 of 1.\n",
      "  - Text: 【5†source】\n",
      "  - URL: https://www.accuweather.com/en/au/sydney/22889/january-weather/22889\n",
      "Deleting agent asst_YaekF8FSleVzbWKhY2Mz58in...\n",
      "---------- bingsearch_assistant ----------\n",
      "[FunctionCall(id='call_rVDyeudq85Tf2ZxlojnmPDjb', arguments='{\"query\": \"expected minimum and maximum temperature in Rome tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_sYhzxhleXuGC95iUbtQY0bmx', arguments='{\"query\": \"expected minimum and maximum temperature in Moscow tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_ESySYQUmfGIKciboG4IUEXh9', arguments='{\"query\": \"expected minimum and maximum temperature in Sydney tomorrow\"}', name='web_ai_agent')]\n",
      "---------- bingsearch_assistant ----------\n",
      "[FunctionExecutionResult(content='The weather forecast for Rome on January 21, 2025, predicts a minimum temperature of 6°C and a maximum temperature of 12°C【5†source】.', call_id='call_rVDyeudq85Tf2ZxlojnmPDjb'), FunctionExecutionResult(content='In Moscow, on January 21, 2025, the expected minimum temperature is -2°C and the maximum temperature is 1°C【5†source】.', call_id='call_sYhzxhleXuGC95iUbtQY0bmx'), FunctionExecutionResult(content='The expected minimum and maximum temperatures in Sydney tomorrow, January 21, 2025, are approximately 21°C and 26°C【5†source】.', call_id='call_ESySYQUmfGIKciboG4IUEXh9')]\n",
      "---------- bingsearch_assistant ----------\n",
      "The weather forecast for Rome on January 21, 2025, predicts a minimum temperature of 6°C and a maximum temperature of 12°C【5†source】.\n",
      "In Moscow, on January 21, 2025, the expected minimum temperature is -2°C and the maximum temperature is 1°C【5†source】.\n",
      "The expected minimum and maximum temperatures in Sydney tomorrow, January 21, 2025, are approximately 21°C and 26°C【5†source】.\n",
      "This is CodeInterpreter for Azure AI Agent Service...\n",
      "Created CODE INTERPRETER agent, ID: asst_FfvXeolQWNeK2oGQjZk2brW8\n",
      "Created thread, ID: thread_xtmRCCBRfFd4Jj77FWZguAyD\n",
      "Created message, ID: msg_6A2ZLU4uSZF3BcLDXvdeT7aQ\n",
      "Run finished with status: RunStatus.COMPLETED. Run id: run_pGY4hlfEGTE8GpG3Ib6mB3ds\n",
      "Here is the content of the last message:\n",
      "CONTENT 1 (MessageImageFileContent) --> image_file id: assistant-U5i0YYBCePL2jKBTKMkdgF5d\n",
      "CONTENT 2 (MessageTextContent) --> Text: Here is the bar chart comparing the minimum and maximum temperatures for tomorrow in Rome, Moscow, and Sydney. The chart is also saved as a file named `temperature_chart.png`, which you can download [here](sandbox:/mnt/data/temperature_chart.png).\n",
      ">>> Annotation in MessageTextContent 2: sandbox:/mnt/data/temperature_chart.png\n",
      "\n",
      "Nr. of file path annotations: 1\n",
      "1 - File annotation paths: {'type': 'file_path', 'text': 'sandbox:/mnt/data/temperature_chart.png', 'start_index': 206, 'end_index': 245, 'file_path': {'file_id': 'assistant-9PM6a7FJ6NBl8uho1R2zk1Iq'}}\n",
      "File annoation 1 saved as file to: E:\\Users\\mauromi\\source\\git_repos\\aaas\\temperature_chart.png\n",
      "Nr. of image contents: 1\n",
      "\n",
      "1 - Image content: {'type': 'image_file', 'image_file': {'file_id': 'assistant-U5i0YYBCePL2jKBTKMkdgF5d'}}\n",
      "Image content 1 file to: E:\\Users\\mauromi\\source\\git_repos\\aaas\\assistant-U5i0YYBCePL2jKBTKMkdgF5d_image_content.png\n",
      "Deleting agent asst_FfvXeolQWNeK2oGQjZk2brW8...\n",
      "---------- codeinterpreter_assistant ----------\n",
      "[FunctionCall(id='call_OGEo1qcqVyKbPdONWyEeQFkT', arguments='{\"action\":\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the bar chart\\\\ncities = [\\'Rome\\', \\'Moscow\\', \\'Sydney\\']\\\\nmin_temps = [6, -2, 21]\\\\nmax_temps = [12, 1, 26]\\\\n\\\\n# Create a bar chart\\\\nx = range(len(cities))  # the label locations\\\\nwidth = 0.35  # the width of the bars\\\\n\\\\nfig, ax = plt.subplots()\\\\nrects1 = ax.bar(x, min_temps, width, label=\\'Min Temp\\')\\\\nrects2 = ax.bar([p + width for p in x], max_temps, width, label=\\'Max Temp\\')\\\\n\\\\n# Add some text for labels, title and custom x-axis tick labels, etc.\\\\nax.set_ylabel(\\'Temperature (°C)\\')\\\\nax.set_title(\\'Min and Max Temperatures for Tomorrow\\')\\\\nax.set_xticks([p + width/2 for p in x])\\\\nax.set_xticklabels(cities)\\\\nax.legend()\\\\n\\\\n# Save the plot as a file\\\\nplt.savefig(\\'/mnt/data/temperature_chart.png\\')\\\\nplt.show()\"}', name='codeinterpreter_ai_agent')]\n",
      "---------- codeinterpreter_assistant ----------\n",
      "[FunctionExecutionResult(content='Here is the bar chart comparing the minimum and maximum temperatures for tomorrow in Rome, Moscow, and Sydney. The chart is also saved as a file named `temperature_chart.png`, which you can download [here](sandbox:/mnt/data/temperature_chart.png).', call_id='call_OGEo1qcqVyKbPdONWyEeQFkT')]\n",
      "---------- codeinterpreter_assistant ----------\n",
      "Here is the bar chart comparing the minimum and maximum temperatures for tomorrow in Rome, Moscow, and Sydney. The chart is also saved as a file named `temperature_chart.png`, which you can download [here](sandbox:/mnt/data/temperature_chart.png).\n",
      "---------- italiantranslator_assistant ----------\n",
      "Ecco la traduzione in italiano:\n",
      "\n",
      "Le previsioni del tempo per Roma il 21 gennaio 2025 prevedono una temperatura minima di 6°C e una temperatura massima di 12°C.\n",
      "A Mosca, il 21 gennaio 2025, la temperatura minima prevista è di -2°C e la temperatura massima è di 1°C.\n",
      "Le temperature minime e massime previste a Sydney domani, 21 gennaio 2025, sono rispettivamente di circa 21°C e 26°C.\n",
      "\n",
      "Qui c'è il grafico a barre che confronta le temperature minime e massime per domani a Roma, Mosca e Sydney. Il grafico è stato salvato come file denominato `temperature_chart.png`, che puoi scaricare [qui](sandbox:/mnt/data/temperature_chart.png).\n",
      "\n",
      "ITALIAN TRANSLATOR IS WILLING TO TERMINATE.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='\\n    First, find the expected min and max temperature tomorrow in Rome, Moscow and Sydney. \\n    Then, create the image of a bar chart for the two temperatures of tomorrow.\\n    Then, download the file on my local PC.\\n    Translate the answer to Italian.\\n    ', type='TextMessage'), ToolCallRequestEvent(source='bingsearch_assistant', models_usage=RequestUsage(prompt_tokens=128, completion_tokens=82), content=[FunctionCall(id='call_rVDyeudq85Tf2ZxlojnmPDjb', arguments='{\"query\": \"expected minimum and maximum temperature in Rome tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_sYhzxhleXuGC95iUbtQY0bmx', arguments='{\"query\": \"expected minimum and maximum temperature in Moscow tomorrow\"}', name='web_ai_agent'), FunctionCall(id='call_ESySYQUmfGIKciboG4IUEXh9', arguments='{\"query\": \"expected minimum and maximum temperature in Sydney tomorrow\"}', name='web_ai_agent')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='bingsearch_assistant', models_usage=None, content=[FunctionExecutionResult(content='The weather forecast for Rome on January 21, 2025, predicts a minimum temperature of 6°C and a maximum temperature of 12°C【5†source】.', call_id='call_rVDyeudq85Tf2ZxlojnmPDjb'), FunctionExecutionResult(content='In Moscow, on January 21, 2025, the expected minimum temperature is -2°C and the maximum temperature is 1°C【5†source】.', call_id='call_sYhzxhleXuGC95iUbtQY0bmx'), FunctionExecutionResult(content='The expected minimum and maximum temperatures in Sydney tomorrow, January 21, 2025, are approximately 21°C and 26°C【5†source】.', call_id='call_ESySYQUmfGIKciboG4IUEXh9')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='bingsearch_assistant', models_usage=None, content='The weather forecast for Rome on January 21, 2025, predicts a minimum temperature of 6°C and a maximum temperature of 12°C【5†source】.\\nIn Moscow, on January 21, 2025, the expected minimum temperature is -2°C and the maximum temperature is 1°C【5†source】.\\nThe expected minimum and maximum temperatures in Sydney tomorrow, January 21, 2025, are approximately 21°C and 26°C【5†source】.', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='codeinterpreter_assistant', models_usage=RequestUsage(prompt_tokens=274, completion_tokens=262), content=[FunctionCall(id='call_OGEo1qcqVyKbPdONWyEeQFkT', arguments='{\"action\":\"import matplotlib.pyplot as plt\\\\n\\\\n# Data for the bar chart\\\\ncities = [\\'Rome\\', \\'Moscow\\', \\'Sydney\\']\\\\nmin_temps = [6, -2, 21]\\\\nmax_temps = [12, 1, 26]\\\\n\\\\n# Create a bar chart\\\\nx = range(len(cities))  # the label locations\\\\nwidth = 0.35  # the width of the bars\\\\n\\\\nfig, ax = plt.subplots()\\\\nrects1 = ax.bar(x, min_temps, width, label=\\'Min Temp\\')\\\\nrects2 = ax.bar([p + width for p in x], max_temps, width, label=\\'Max Temp\\')\\\\n\\\\n# Add some text for labels, title and custom x-axis tick labels, etc.\\\\nax.set_ylabel(\\'Temperature (°C)\\')\\\\nax.set_title(\\'Min and Max Temperatures for Tomorrow\\')\\\\nax.set_xticks([p + width/2 for p in x])\\\\nax.set_xticklabels(cities)\\\\nax.legend()\\\\n\\\\n# Save the plot as a file\\\\nplt.savefig(\\'/mnt/data/temperature_chart.png\\')\\\\nplt.show()\"}', name='codeinterpreter_ai_agent')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='codeinterpreter_assistant', models_usage=None, content=[FunctionExecutionResult(content='Here is the bar chart comparing the minimum and maximum temperatures for tomorrow in Rome, Moscow, and Sydney. The chart is also saved as a file named `temperature_chart.png`, which you can download [here](sandbox:/mnt/data/temperature_chart.png).', call_id='call_OGEo1qcqVyKbPdONWyEeQFkT')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='codeinterpreter_assistant', models_usage=None, content='Here is the bar chart comparing the minimum and maximum temperatures for tomorrow in Rome, Moscow, and Sydney. The chart is also saved as a file named `temperature_chart.png`, which you can download [here](sandbox:/mnt/data/temperature_chart.png).', type='ToolCallSummaryMessage'), TextMessage(source='italiantranslator_assistant', models_usage=RequestUsage(prompt_tokens=286, completion_tokens=181), content=\"Ecco la traduzione in italiano:\\n\\nLe previsioni del tempo per Roma il 21 gennaio 2025 prevedono una temperatura minima di 6°C e una temperatura massima di 12°C.\\nA Mosca, il 21 gennaio 2025, la temperatura minima prevista è di -2°C e la temperatura massima è di 1°C.\\nLe temperature minime e massime previste a Sydney domani, 21 gennaio 2025, sono rispettivamente di circa 21°C e 26°C.\\n\\nQui c'è il grafico a barre che confronta le temperature minime e massime per domani a Roma, Mosca e Sydney. Il grafico è stato salvato come file denominato `temperature_chart.png`, che puoi scaricare [qui](sandbox:/mnt/data/temperature_chart.png).\\n\\nITALIAN TRANSLATOR IS WILLING TO TERMINATE.\", type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The group chat will alternate between the assistant and the code executor.\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "group_chat = RoundRobinGroupChat([bingsearch_assistant, codeinterpreter_assistant, italiantranslator_assistant], termination_condition=termination)\n",
    "\n",
    "stream = group_chat.run_stream(task=\"\"\"\n",
    "    First, find the expected min and max temperature tomorrow in Rome, Moscow and Sydney. \n",
    "    Then, create the image of a bar chart for the two temperatures of tomorrow.\n",
    "    Then, download the file on my local PC.\n",
    "    Translate the answer to Italian.\n",
    "    \"\"\")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ec759-c053-4ab7-81aa-15cfa4961468",
   "metadata": {},
   "source": [
    "# START Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48399858-16e3-4b7c-a13a-aa3ed8320539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 agent(s) will now be deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete all agents\n",
    "\n",
    "print(f\"{len(project_client.agents.list_agents()['data'])} agent(s) will now be deleted\")\n",
    "\n",
    "i=0\n",
    "for pca in project_client.agents.list_agents()['data']:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(pca.id)\n",
    "    print(f\"\\n{i} - Agent {pca.name} has been deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc2b04-a0b3-45ee-9066-4306e16511f9",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
