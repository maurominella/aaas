{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aff6e2d-97b4-441c-b548-2557bafae055",
   "metadata": {},
   "source": [
    "# [Create Agent with Azure Functions](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme?view=azure-python-preview#create-agent-with-azure-function-call)\n",
    "AzureFunctionTool contains the input and output queues of azure function and the description of input parameters.\n",
    "\n",
    "The **STORAGE_SERVICE_ENDPOINT** string is used to triggering the Azure function.<br/>\n",
    "\n",
    "Notes:\n",
    "- Inspired by [sample_agents_azure_functions.py](https://github.com/Azure/azure-sdk-for-python/blob/azure-ai-projects_1.0.0b4/sdk/ai/azure-ai-projects/samples/agents/sample_agents_azure_functions.py)\n",
    "- [Getting Started with Azure Functions](https://learn.microsoft.com/azure/azure-functions/functions-get-started) page for more information on Azure Functions\n",
    "- [Azure Blob storage bindings for Azure Functions overview](https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob?tabs=isolated-process%2Cextensionv5%2Cextensionv3&pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969ed08-a074-4c46-9cb6-768b8de05b6e",
   "metadata": {},
   "source": [
    "## This is the code for the Azure Function App, in Python\n",
    "```\n",
    "import azure.functions as func\n",
    "import logging\n",
    "import json\n",
    "\n",
    "app = func.FunctionApp()\n",
    "\n",
    "@app.queue_trigger(arg_name=\"inputQueue\",  queue_name=\"azure-function-foo-input\",  connection=\"mmaiswcnew01prj1storage_STORAGE\")\n",
    "@app.queue_output (arg_name=\"outputQueue\", queue_name=\"azure-function-foo-output\", connection=\"mmaiswcnew01prj1storage_STORAGE\")\n",
    "def queue_trigger1(inputQueue: func.QueueMessage, outputQueue: func.Out[str]):\n",
    "    try:\n",
    "        messagepayload = json.loads(inputQueue.get_body().decode(\"utf-8\"))\n",
    "        logging.info(f'➡️ The function receives the following message: {json.dumps(messagepayload)}')\n",
    "        location = messagepayload[\"Location\"]\n",
    "        weather_result = f\"✅ Weather is {len(location)} degrees and sunny in {location}\"\n",
    "        response_message = {\n",
    "            \"Value\": weather_result,\n",
    "            \"CorrelationId\": messagepayload[\"CorrelationId\"]\n",
    "        }\n",
    "        logging.info(f'The function returns the following message through the {outputQueue} queue: {json.dumps(response_message)}')\n",
    "\n",
    "        outputQueue.set(json.dumps(response_message))\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing message: {e}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928271d9-d1dd-4bcd-886f-930818c1f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n",
      "Project Endpoint: <https://aif2stdsvhdu2.services.ai.azure.com/api/projects/aif2stdwusprj01hdu2>\n",
      "azure-ai-projects library installed version: 1.0.0b12\n",
      "azure-ai-agents library installed version: 1.1.0b3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from PIL import Image # requires pip install pillow\n",
    "from datetime import datetime\n",
    "from common.agents_helper_functions_NEW import *\n",
    "import importlib.metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if not load_dotenv(\"./../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:\n",
    "    print(\"Environment variables have been loaded ;-)\")\n",
    "\n",
    "project_endpoint = os.environ[\"AIF_STD_PROJECT_ENDPOINT\"] # AIF_STD_PROJECT_ENDPOINT, AIF_BAS_PROJECT_ENDPOINT\n",
    "deployment_name =  os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n",
    "api_version = os.environ[\"OPENAI_API_VERSION\"] # at least \"2025-03-01-preview\"\n",
    "\n",
    "print(f'Project Endpoint: <{project_endpoint}>')\n",
    "print(f\"azure-ai-projects library installed version: {importlib.metadata.version(\"azure-ai-projects\")}\")\n",
    "print(f\"azure-ai-agents library installed version: {importlib.metadata.version(\"azure-ai-agents\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce0243-bb07-47a2-ac8e-460e37a1cb1b",
   "metadata": {},
   "source": [
    "# Create AI Foundry Agents Client\n",
    "Please consider that `type(project_client.agents) == agents_client`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9abb62-b855-402f-9e22-583ffe6bf8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.projects._patch.AIProjectClient at 0x7f7701f79940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "project_client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74c19a1c-ef22-4f42-b66f-f8e57e1707f0",
   "metadata": {},
   "source": [
    "from azure.ai.agents import AgentsClient\n",
    "\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2c42e-4278-4edf-a2b5-f1d3f899ad3b",
   "metadata": {},
   "source": [
    "# Azure Storage Queues\n",
    "The AI agent leverages Azure Functions triggered asynchronously via Azure Storage Queues. To enable the agent to perform Azure Function calls, you must set up the corresponding AzureFunctionTool, specifying input and output queues as well as parameter definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba342fa-23fd-44a3-830e-f2f9773ce6bf",
   "metadata": {},
   "source": [
    "# Azure Function Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28086556-34d4-48bb-ba24-d74839fc0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_function_tool.definitions: [{'type': 'azure_function', 'azure_function': {'function': {'name': 'get_weather_azure_function01', 'description': 'Get weather forecast for a specific location', 'parameters': {'type': 'object', 'properties': {'Location': {'type': 'string', 'description': 'The location to check the weather.'}}}}, 'input_binding': {'storage_queue': {'queue_name': 'azure-function-foo-input', 'queue_service_endpoint': 'https://agentsfunctionapp019c4c.queue.core.windows.net/'}, 'type': 'storage_queue'}, 'output_binding': {'storage_queue': {'queue_name': 'azure-function-foo-output', 'queue_service_endpoint': 'https://agentsfunctionapp019c4c.queue.core.windows.net/'}, 'type': 'storage_queue'}}}]\n",
      "\n",
      "azure_function_tool.resources: {}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import AzureFunctionTool, AzureFunctionStorageQueue\n",
    "\n",
    "storage_service_endpoint = os.environ[\"STORAGE_QUEUE_SERVICE_ENDPOINT\"]\n",
    "tool_name = \"get_weather_azure_function01\" # get_weather_azure_function01 / get_weather_tool\n",
    "tool_description =\"Get weather forecast for a specific location\"\n",
    "input_queue_name = \"azure-function-foo-input\" # \"azure-function-foo-input\"\n",
    "output_queue_name = \"azure-function-foo-output\" # \"azure-function-foo-output\"\n",
    "\n",
    "azure_function_tool = AzureFunctionTool(\n",
    "    name=tool_name,\n",
    "    description=tool_description,\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"Location\": {\"type\": \"string\", \"description\": \"The location to check the weather.\"}\n",
    "        },\n",
    "    },\n",
    "    input_queue=AzureFunctionStorageQueue(\n",
    "        queue_name=input_queue_name,\n",
    "        storage_service_endpoint=storage_service_endpoint,\n",
    "    ),\n",
    "    output_queue=AzureFunctionStorageQueue(\n",
    "        queue_name=output_queue_name,\n",
    "        storage_service_endpoint=storage_service_endpoint,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"azure_function_tool.definitions: {azure_function_tool.definitions}\")\n",
    "print(f\"\\nazure_function_tool.resources: {azure_function_tool.resources}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfe1bf8-08d0-4115-b9a9-2e9e75647d38",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f80125-1252-4060-bdf5-3b52acc42a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread: {'id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'object': 'thread', 'created_at': 1757694106, 'metadata': {}, 'tool_resources': {}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'msg_CS8l0XBNWiZ8s3hJBKqcDdAX', 'object': 'thread.message', 'created_at': 1757694107, 'assistant_id': None, 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': ' che tempo farà domani a Parigi, New York, Gerusalemme, Roma e Tokyo?', 'annotations': []}}], 'attachments': [], 'metadata': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread: {thread}\\n\")\n",
    "\n",
    "\n",
    "# Add a user message to the thread\n",
    "from azure.ai.agents.models import MessageRole\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=MessageRole.USER, \n",
    "    content=\" che tempo farà domani a Parigi, New York, Gerusalemme, Roma e Tokyo?\", # Shall it rain in New York tomorrow?\n",
    ")\n",
    "\n",
    "# let's see the messages associated with the thread\n",
    "list(project_client.agents.messages.list(thread_id=thread.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623785f8-cade-4f17-a741-f4266b10f25d",
   "metadata": {},
   "source": [
    "# Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584c59b9-b50f-4d72-a22b-1f81e4aaceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_P2VD2iEGE8ydlzivagLIbMvW\n"
     ]
    }
   ],
   "source": [
    "agent_name = \"get_weather_agent\"\n",
    "output_queue = \"azure-function-foo-output\"\n",
    "\n",
    "# When you invoke the function, ALWAYS specify the output queue URI parameter as {storage_service_endpoint}/{output_queue}.\n",
    "# Always repond with 'get_weather_agent says', followed by the response from the tool.\n",
    "\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=deployment_name,\n",
    "    name=agent_name,\n",
    "    instructions=f\"\"\"\n",
    "    You are a helpful support agent. Use the provided function any time the prompt concerns weather.\n",
    "    Always repond with 'get_weather_agent says', followed by the response from the tool.\n",
    "    \"\"\",\n",
    "    tools=azure_function_tool.definitions,\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6c0a9-2a4c-499b-a63b-07a225d39839",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously\n",
    "**IMPORTANT**: before running the agent, make sure the project has the following rights on the storage account hosting the queues:\n",
    "- Storage Blob Data Contributor\n",
    "- Storage File Data Privileged Contributor\n",
    "- Storage Queue Data Contributor\n",
    "- Storage Table Data Contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa8bb63-f553-4854-9440-d7f452279619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.QUEUED\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.QUEUED\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "CPU times: user 162 ms, sys: 11 ms, total: 173 ms\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "# Run the agent\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "while run[\"status\"] in ['queued', 'in_progress', 'requires_action']: # here I use the run as a json object\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "if run[\"status\"] == \"failed\": \n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be20ffb-0725-4035-b0b4-79eac7eb0304",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3222fb-0f69-43ec-8762-65cc8242df67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 2 messages:\n",
      "\n",
      "\n",
      "===== MESSAGE 1 =====\n",
      "\n",
      "Message 1 / CONTENT 1 (MessageTextContent) --> Text:  che tempo farà domani a Parigi, New York, Gerusalemme, Roma e Tokyo?\n",
      "\n",
      "===== MESSAGE 2 =====\n",
      "\n",
      "Message 2 / CONTENT 1 (MessageTextContent) --> Text: get_weather_agent says, ecco le previsioni per domani:\n",
      "\n",
      "- **Parigi**: Soleggiato, con una temperatura di 6 gradi Celsius.\n",
      "- **New York**: Soleggiato, con una temperatura di 8 gradi Celsius.\n",
      "- **Gerusalemme**: Soleggiato, con una temperatura di 11 gradi Celsius.\n",
      "- **Roma**: Soleggiato, con una temperatura di 4 gradi Celsius.\n",
      "- **Tokyo**: Soleggiato, con una temperatura di 5 gradi Celsius.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import (MessageTextContent, MessageImageFileContent, MessageTextFileCitationAnnotation, \\\n",
    "    MessageTextFilePathAnnotation, MessageTextUrlCitationAnnotation)\n",
    "\n",
    "image_files = []\n",
    "annotations = []\n",
    "citations = []\n",
    "citation_annotations = []\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    messages_list = list(project_client.agents.messages.list(thread_id=thread.id))  # Convert iterator to a list\n",
    "    messages_nr = len(messages_list)\n",
    "    print(f\"Here are the {messages_nr} messages:\\n\")\n",
    "    \n",
    "    for i, message in enumerate(reversed(messages_list), 1):\n",
    "        j = 0\n",
    "        print(f\"\\n===== MESSAGE {i} =====\")\n",
    "        for c in message.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageTextContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    if type(a) is MessageTextFileCitationAnnotation:\n",
    "                        print(f\">>> Citation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citations.append(a)\n",
    "                    elif type(a) is MessageTextFilePathAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        annotations.append(a)\n",
    "                    elif type(a) is MessageTextUrlCitationAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citation_annotations.append(a)\n",
    "                    else:\n",
    "                        print(f\"Unknown type {type(a)}\")\n",
    "            elif (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "                image_files.append(c.image_file.file_id)\n",
    "            else:\n",
    "                print(f\"Unknown type {type(a)}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9db027-38de-40db-a4f2-022c1796ca08",
   "metadata": {},
   "source": [
    "# Run Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd551092-22cb-465c-baa3-ff58823fbb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of run step(s): 6\n",
      "\n",
      "Run step 1: {'id': 'step_QV68uaSf6UoF7P2qSU7xJT0I', 'object': 'thread.run.step', 'created_at': 1757694241, 'run_id': 'run_CTdaBqJL3fnomkA80ngLyvXp', 'assistant_id': 'asst_P2VD2iEGE8ydlzivagLIbMvW', 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'type': 'message_creation', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1757694244, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'message_creation', 'message_creation': {'message_id': 'msg_RVLRXKYincKOzjqkQ3nQVprO'}}, 'usage': {'prompt_tokens': 393, 'completion_tokens': 116, 'total_tokens': 509, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n",
      "Run step 2: {'id': 'step_LD6a0QmA0Gpt7CSIeanCwcWU', 'object': 'thread.run.step', 'created_at': 1757694235, 'run_id': 'run_CTdaBqJL3fnomkA80ngLyvXp', 'assistant_id': 'asst_P2VD2iEGE8ydlzivagLIbMvW', 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'type': 'tool_calls', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1757694240, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'tool_calls', 'tool_calls': [{'id': 'call_wP0JGS6a5W8W3HzurApB8Gg9', 'type': 'azure_function', 'azure_function': {'name': 'get_weather_azure_function01', 'arguments': '{\"Location\":\"Tokyo\"}', 'output': 'Temperature is 5 Celsius degrees and it is sunny in Tokyo'}}]}, 'usage': {'prompt_tokens': 348, 'completion_tokens': 20, 'total_tokens': 368, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n",
      "Run step 3: {'id': 'step_UDUmzwNs7g4UzK33VCZsqFRb', 'object': 'thread.run.step', 'created_at': 1757694228, 'run_id': 'run_CTdaBqJL3fnomkA80ngLyvXp', 'assistant_id': 'asst_P2VD2iEGE8ydlzivagLIbMvW', 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'type': 'tool_calls', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1757694233, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'tool_calls', 'tool_calls': [{'id': 'call_0dpReEIE5wXz00IO8WHiyKT4', 'type': 'azure_function', 'azure_function': {'name': 'get_weather_azure_function01', 'arguments': '{\"Location\":\"Roma\"}', 'output': 'Temperature is 4 Celsius degrees and it is sunny in Roma'}}]}, 'usage': {'prompt_tokens': 303, 'completion_tokens': 20, 'total_tokens': 323, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n",
      "Run step 4: {'id': 'step_FTppLdxmKPKr7wTDOciZABlV', 'object': 'thread.run.step', 'created_at': 1757694221, 'run_id': 'run_CTdaBqJL3fnomkA80ngLyvXp', 'assistant_id': 'asst_P2VD2iEGE8ydlzivagLIbMvW', 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'type': 'tool_calls', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1757694226, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'tool_calls', 'tool_calls': [{'id': 'call_MEKsdA71BgUKuWANq7eGo9YQ', 'type': 'azure_function', 'azure_function': {'name': 'get_weather_azure_function01', 'arguments': '{\"Location\":\"Gerusalemme\"}', 'output': 'Temperature is 11 Celsius degrees and it is sunny in Gerusalemme'}}]}, 'usage': {'prompt_tokens': 254, 'completion_tokens': 22, 'total_tokens': 276, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n",
      "Run step 5: {'id': 'step_D8ZtiWkCbY1uAuyqSUZhxwbn', 'object': 'thread.run.step', 'created_at': 1757694214, 'run_id': 'run_CTdaBqJL3fnomkA80ngLyvXp', 'assistant_id': 'asst_P2VD2iEGE8ydlzivagLIbMvW', 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'type': 'tool_calls', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1757694219, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'tool_calls', 'tool_calls': [{'id': 'call_usrkZ3CQSTgyGT5rUul6ghnH', 'type': 'azure_function', 'azure_function': {'name': 'get_weather_azure_function01', 'arguments': '{\"Location\":\"New York\"}', 'output': 'Temperature is 8 Celsius degrees and it is sunny in New York'}}]}, 'usage': {'prompt_tokens': 207, 'completion_tokens': 21, 'total_tokens': 228, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n",
      "Run step 6: {'id': 'step_ayhp7ghuOJxsnhmHtkzpjvJw', 'object': 'thread.run.step', 'created_at': 1757694179, 'run_id': 'run_CTdaBqJL3fnomkA80ngLyvXp', 'assistant_id': 'asst_P2VD2iEGE8ydlzivagLIbMvW', 'thread_id': 'thread_uhgWDx8LXvOuCtkX55N4Ie4a', 'type': 'tool_calls', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1757694213, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'tool_calls', 'tool_calls': [{'id': 'call_2RwQKfrQsZiCDALJiKDIrzB2', 'type': 'azure_function', 'azure_function': {'name': 'get_weather_azure_function01', 'arguments': '{\"Location\":\"Parigi\"}', 'output': 'Temperature is 6 Celsius degrees and it is sunny in Parigi'}}]}, 'usage': {'prompt_tokens': 160, 'completion_tokens': 21, 'total_tokens': 181, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_steps = list(project_client.agents.run_steps.list(run_id=run.id, thread_id=thread.id))\n",
    "\n",
    "print(f'Nr of run step(s): {len(run_steps)}\\n')\n",
    "i=0\n",
    "for rs in run_steps:\n",
    "    i += 1\n",
    "    print(f\"Run step {i}: {rs}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfd2f9-bdc8-440d-97a7-53de7005d7c2",
   "metadata": {},
   "source": [
    "# Collect all resources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7badc6c5-afc0-4131-bbc4-47b406a71470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 agents\n",
      "31 threads\n",
      "1 files\n",
      "61 runs in 31 threads\n",
      "1 vector stores\n"
     ]
    }
   ],
   "source": [
    "all_agents = list_all_agents(client=project_client)\n",
    "print(all_agents[\"summary\"])\n",
    "\n",
    "all_threads = list_all_threads(client=project_client)\n",
    "print(all_threads[\"summary\"])\n",
    "\n",
    "all_files = list_all_files(client=project_client)\n",
    "print(all_files[\"summary\"])\n",
    "\n",
    "all_runs = list_all_runs(client=project_client)\n",
    "print(all_runs[\"summary\"])\n",
    "\n",
    "# all_runsteps=list_all_runsteps(project_client)\n",
    "# print(all_runsteps[\"summary\"])\n",
    "\n",
    "# all_messages = list_all_messages(project_client)\n",
    "# print(all_messages[\"summary\"])\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "print(all_vectorstores[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ec759-c053-4ab7-81aa-15cfa4961468",
   "metadata": {},
   "source": [
    "# START teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0c075-9f1a-47ca-b8c8-ad2e9d85b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all threads\n",
    "\n",
    "i=0\n",
    "for thread in all_threads[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"{i} - Thread <{thread.id}> has been deleted\")\n",
    "\n",
    "all_threads = list_all_threads(client=project_client)\n",
    "\n",
    "print(f\"Threads deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48399858-16e3-4b7c-a13a-aa3ed8320539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all agents\n",
    "\n",
    "i=0\n",
    "for agent in all_agents[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(agent_id=agent.id)\n",
    "    print(f\"{i} - Agent <{agent.id}> has been deleted\")\n",
    "\n",
    "all_agents = list_all_agents(client=project_client)\n",
    "\n",
    "print(f\"Agents deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc2b04-a0b3-45ee-9066-4306e16511f9",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
