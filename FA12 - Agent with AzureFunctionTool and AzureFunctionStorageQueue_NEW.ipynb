{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aff6e2d-97b4-441c-b548-2557bafae055",
   "metadata": {},
   "source": [
    "# [Create Agent with Azure Functions](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme?view=azure-python-preview#create-agent-with-azure-function-call)\n",
    "AzureFunctionTool contains the input and output queues of azure function and the description of input parameters.\n",
    "\n",
    "The **STORAGE_SERVICE_ENDPOINT** string is used to triggering the Azure function.<br/>\n",
    "\n",
    "Notes:\n",
    "- Inspired by [sample_agents_azure_functions.py](https://github.com/Azure/azure-sdk-for-python/blob/azure-ai-projects_1.0.0b4/sdk/ai/azure-ai-projects/samples/agents/sample_agents_azure_functions.py)\n",
    "- [Getting Started with Azure Functions](https://learn.microsoft.com/azure/azure-functions/functions-get-started) page for more information on Azure Functions\n",
    "- [Azure Blob storage bindings for Azure Functions overview](https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob?tabs=isolated-process%2Cextensionv5%2Cextensionv3&pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a20c0-1768-4c6a-a9fb-fb79abf71ee2",
   "metadata": {},
   "source": [
    "## This is the code for the Azure Function App\n",
    "```\n",
    "import azure.functions as func\n",
    "import logging\n",
    "import json\n",
    "\n",
    "app = func.FunctionApp()\n",
    "\n",
    "@app.queue_trigger(arg_name=\"inputQueue\",  queue_name=\"azure-function-foo-input\",  connection=\"mmaiswcnew01prj1storage_STORAGE\")\n",
    "@app.queue_output (arg_name=\"outputQueue\", queue_name=\"azure-function-foo-output\", connection=\"mmaiswcnew01prj1storage_STORAGE\")\n",
    "def queue_trigger1(inputQueue: func.QueueMessage, outputQueue: func.Out[str]):\n",
    "    try:\n",
    "        messagepayload = json.loads(inputQueue.get_body().decode(\"utf-8\"))\n",
    "        logging.info(f'➡️ The function receives the following message: {json.dumps(messagepayload)}')\n",
    "        location = messagepayload[\"location\"]\n",
    "        weather_result = f\"✅ Weather is {len(location)} degrees and sunny in {location}\"\n",
    "        response_message = {\n",
    "            \"Value\": weather_result,\n",
    "            \"CorrelationId\": messagepayload[\"CorrelationId\"]\n",
    "        }\n",
    "        logging.info(f'The function returns the following message through the {outputQueue} queue: {json.dumps(response_message)}')\n",
    "\n",
    "        outputQueue.set(json.dumps(response_message))\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing message: {e}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d9cc9d-cbef-4b35-a4a3-84802dd4ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n",
      "Project Endpoint: <https://aiservicesiyva.services.ai.azure.com/api/projects/newstrdproject01iyva>\n",
      "azure-ai-projects library installed version: 1.0.0b11\n",
      "azure-ai-agents library installed version: 1.1.0b1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from PIL import Image # requires pip install pillow\n",
    "from datetime import datetime\n",
    "from common.agents_helper_functions_NEW import *\n",
    "import importlib.metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if not load_dotenv(\"./../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:\n",
    "    print(\"Environment variables have been loaded ;-)\")\n",
    "\n",
    "project_endpoint = os.environ[\"AZURE_AIF_PROJECT_ENDPOINT\"]\n",
    "deployment_name =  os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n",
    "api_version = os.environ[\"OPENAI_API_VERSION\"] # at least \"2025-03-01-preview\"\n",
    "\n",
    "print(f'Project Endpoint: <{project_endpoint}>')\n",
    "print(f\"azure-ai-projects library installed version: {importlib.metadata.version(\"azure-ai-projects\")}\")\n",
    "print(f\"azure-ai-agents library installed version: {importlib.metadata.version(\"azure-ai-agents\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce0243-bb07-47a2-ac8e-460e37a1cb1b",
   "metadata": {},
   "source": [
    "# Create AI Foundry Agents Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9abb62-b855-402f-9e22-583ffe6bf8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.agents._patch.AgentsClient at 0x70aa6764d400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "agents_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2c42e-4278-4edf-a2b5-f1d3f899ad3b",
   "metadata": {},
   "source": [
    "# Azure Storage Queues\n",
    "The AI agent leverages Azure Functions triggered asynchronously via Azure Storage Queues. To enable the agent to perform Azure Function calls, you must set up the corresponding AzureFunctionTool, specifying input and output queues as well as parameter definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba342fa-23fd-44a3-830e-f2f9773ce6bf",
   "metadata": {},
   "source": [
    "# Azure Function Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28086556-34d4-48bb-ba24-d74839fc0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_function_tool.definitions: [{'type': 'azure_function', 'azure_function': {'function': {'name': 'get_weather_tool', 'description': 'Get weather forecast for a specific location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location to check the weather.'}, 'outputqueueuri': {'type': 'string', 'description': 'The full output queue uri.'}}}}, 'input_binding': {'storage_queue': {'queue_name': 'azure-function-foo-input', 'queue_service_endpoint': 'https://mmaiswcnew01prj1storage.queue.core.windows.net/'}, 'type': 'storage_queue'}, 'output_binding': {'storage_queue': {'queue_name': 'azure-function-foo-output', 'queue_service_endpoint': 'https://mmaiswcnew01prj1storage.queue.core.windows.net/'}, 'type': 'storage_queue'}}}]\n",
      "\n",
      "azure_function_tool.resources: {}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import AzureFunctionTool, AzureFunctionStorageQueue\n",
    "\n",
    "storage_service_endpoint = os.environ[\"STORAGE_QUEUE_SERVICE_ENDPOINT\"]\n",
    "tool_name = \"get_weather_tool\"\n",
    "tool_description =\"Get weather forecast for a specific location\"\n",
    "input_queue_name = \"azure-function-foo-input\" # \"azure-function-foo-input\"\n",
    "output_queue_name = \"azure-function-foo-output\" # \"azure-function-foo-output\"\n",
    "\n",
    "azure_function_tool = AzureFunctionTool(\n",
    "    name=tool_name,\n",
    "    description=tool_description,\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\", \"description\": \"The location to check the weather.\"},\n",
    "            \"outputqueueuri\": {\"type\": \"string\", \"description\": \"The full output queue uri.\"},\n",
    "        },\n",
    "    },\n",
    "    input_queue=AzureFunctionStorageQueue(\n",
    "        queue_name=input_queue_name,\n",
    "        storage_service_endpoint=storage_service_endpoint,\n",
    "    ),\n",
    "    output_queue=AzureFunctionStorageQueue(\n",
    "        queue_name=output_queue_name,\n",
    "        storage_service_endpoint=storage_service_endpoint,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"azure_function_tool.definitions: {azure_function_tool.definitions}\")\n",
    "print(f\"\\nazure_function_tool.resources: {azure_function_tool.resources}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfe1bf8-08d0-4115-b9a9-2e9e75647d38",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f80125-1252-4060-bdf5-3b52acc42a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread: {'id': 'thread_chQljNjcnecr2J578EFnQgWY', 'object': 'thread', 'created_at': 1748819985, 'metadata': {}, 'tool_resources': {}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'msg_hhrfPA01V6vxIROlzdSO62Lu', 'object': 'thread.message', 'created_at': 1748819986, 'assistant_id': None, 'thread_id': 'thread_chQljNjcnecr2J578EFnQgWY', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Shall it rain in New York tomorrow?', 'annotations': []}}], 'attachments': [], 'metadata': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = agents_client.threads.create()\n",
    "print(f\"Created thread: {thread}\\n\")\n",
    "\n",
    "\n",
    "# Add a user message to the thread\n",
    "from azure.ai.agents.models import MessageRole\n",
    "\n",
    "message = agents_client.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=MessageRole.USER, \n",
    "    content=\"Shall it rain in New York tomorrow?\",\n",
    ")\n",
    "\n",
    "# let's see the messages associated with the thread\n",
    "list(agents_client.messages.list(thread_id=thread.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623785f8-cade-4f17-a741-f4266b10f25d",
   "metadata": {},
   "source": [
    "# Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584c59b9-b50f-4d72-a22b-1f81e4aaceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_oSrEExVa78HvAI1sM6Vg52yh\n"
     ]
    }
   ],
   "source": [
    "agent_name = \"get_weather_agent\"\n",
    "output_queue = \"azure-function-foo-output\"\n",
    "\n",
    "# When you invoke the function, ALWAYS specify the output queue URI parameter as {storage_service_endpoint}/{output_queue}.\n",
    "# Always repond with 'get_weather_agent says', followed by the response from the tool.\n",
    "\n",
    "agent = agents_client.create_agent(\n",
    "    model=deployment_name,\n",
    "    name=agent_name,\n",
    "    instructions=f\"\"\"\n",
    "    You are a helpful support agent. Use the provided function any time the prompt concerns weather.\n",
    "    When you invoke the function, ALWAYS specify the output queue URI parameter as {storage_service_endpoint}{output_queue}.\n",
    "    Always repond with 'get_weather_agent says', followed by the response from the tool.\n",
    "    \"\"\",\n",
    "    tools=azure_function_tool.definitions,\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6c0a9-2a4c-499b-a63b-07a225d39839",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously\n",
    "**IMPORTANT**: before running the agent, make sure the project has the following rights on the storage account hosting the queues:\n",
    "- Storage Blob Data Contributor\n",
    "- Storage File Data Privileged Contributor\n",
    "- Storage Queue Data Contributor\n",
    "- Storage Table Data Contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a6d700-4005-4bb1-a626-64b268a5d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED.\n",
      "\n",
      "Run: {'id': 'run_x9HpP9OyY3MwKJJarMDbd47I', 'object': 'thread.run', 'created_at': 1748819993, 'assistant_id': 'asst_oSrEExVa78HvAI1sM6Vg52yh', 'thread_id': 'thread_chQljNjcnecr2J578EFnQgWY', 'status': 'completed', 'started_at': 1748820027, 'expires_at': None, 'cancelled_at': None, 'failed_at': None, 'completed_at': 1748820027, 'required_action': None, 'last_error': None, 'model': 'gpt-4o', 'instructions': \"\\n    You are a helpful support agent. Use the provided function any time the prompt concerns weather.\\n    When you invoke the function, ALWAYS specify the output queue URI parameter as https://mmaiswcnew01prj1storage.queue.core.windows.net/azure-function-foo-output.\\n    Always repond with 'get_weather_agent says', followed by the response from the tool.\\n    \", 'tools': [{'type': 'azure_function', 'azure_function': {'input_binding': {'type': 'storage_queue', 'storage_queue': {'queue_service_endpoint': 'https://mmaiswcnew01prj1storage.queue.core.windows.net/', 'queue_name': 'azure-function-foo-input'}}, 'output_binding': {'type': 'storage_queue', 'storage_queue': {'queue_service_endpoint': 'https://mmaiswcnew01prj1storage.queue.core.windows.net/', 'queue_name': 'azure-function-foo-output'}}, 'function': {'name': 'get_weather_tool', 'description': 'Get weather forecast for a specific location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location to check the weather.'}, 'outputqueueuri': {'type': 'string', 'description': 'The full output queue uri.'}}}}}}], 'tool_resources': {}, 'metadata': {}, 'temperature': 1.0, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': {'prompt_tokens': 454, 'completion_tokens': 75, 'total_tokens': 529, 'prompt_token_details': {'cached_tokens': 0}}, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}\n",
      "CPU times: user 59.8 ms, sys: 2.24 ms, total: 62.1 ms\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run the agent\n",
    "run = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}.\\n\\nRun: {run}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be20ffb-0725-4035-b0b4-79eac7eb0304",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3222fb-0f69-43ec-8762-65cc8242df67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 2 messages:\n",
      "\n",
      "\n",
      "===== MESSAGE 1 =====\n",
      "\n",
      "Message 1 / CONTENT 1 (MessageTextContent) --> Text: Shall it rain in New York tomorrow?\n",
      "\n",
      "===== MESSAGE 2 =====\n",
      "\n",
      "Message 2 / CONTENT 1 (MessageTextContent) --> Text: get_weather_agent says: The weather in New York tomorrow is expected to be 8 degrees and sunny, so it looks like it won't rain.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import (MessageTextContent, MessageImageFileContent, MessageTextFileCitationAnnotation, \\\n",
    "    MessageTextFilePathAnnotation, MessageTextUrlCitationAnnotation)\n",
    "\n",
    "image_files = []\n",
    "annotations = []\n",
    "citations = []\n",
    "citation_annotations = []\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = agents_client.messages.list(thread_id=thread.id)\n",
    "    messages_list = list(agents_client.messages.list(thread_id=thread.id))  # Convert iterator to a list\n",
    "    messages_nr = len(messages_list)\n",
    "    print(f\"Here are the {messages_nr} messages:\\n\")\n",
    "    \n",
    "    for i, message in enumerate(reversed(messages_list), 1):\n",
    "        j = 0\n",
    "        print(f\"\\n===== MESSAGE {i} =====\")\n",
    "        for c in message.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageTextContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    if type(a) is MessageTextFileCitationAnnotation:\n",
    "                        print(f\">>> Citation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citations.append(a)\n",
    "                    elif type(a) is MessageTextFilePathAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        annotations.append(a)\n",
    "                    elif type(a) is MessageTextUrlCitationAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citation_annotations.append(a)\n",
    "                    else:\n",
    "                        print(f\"Unknown type {type(a)}\")\n",
    "            elif (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "                image_files.append(c.image_file.file_id)\n",
    "            else:\n",
    "                print(f\"Unknown type {type(a)}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9db027-38de-40db-a4f2-022c1796ca08",
   "metadata": {},
   "source": [
    "# Run Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd551092-22cb-465c-baa3-ff58823fbb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of run step(s): 2\n",
      "\n",
      "Run step 1: {'id': 'step_BZSvqToO378hjWC8cZkjufrU', 'object': 'thread.run.step', 'created_at': 1748820027, 'run_id': 'run_x9HpP9OyY3MwKJJarMDbd47I', 'assistant_id': 'asst_oSrEExVa78HvAI1sM6Vg52yh', 'thread_id': 'thread_chQljNjcnecr2J578EFnQgWY', 'type': 'message_creation', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1748820027, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'message_creation', 'message_creation': {'message_id': 'msg_qFSxKNXbALFnwLQQe2JjbSrq'}}, 'usage': {'prompt_tokens': 259, 'completion_tokens': 31, 'total_tokens': 290, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n",
      "Run step 2: {'id': 'step_UyFJW4XyHZxOiUTPWMEtpT92', 'object': 'thread.run.step', 'created_at': 1748819995, 'run_id': 'run_x9HpP9OyY3MwKJJarMDbd47I', 'assistant_id': 'asst_oSrEExVa78HvAI1sM6Vg52yh', 'thread_id': 'thread_chQljNjcnecr2J578EFnQgWY', 'type': 'tool_calls', 'status': 'completed', 'cancelled_at': None, 'completed_at': 1748820026, 'expires_at': None, 'failed_at': None, 'last_error': None, 'step_details': {'type': 'tool_calls', 'tool_calls': [{'id': 'call_pgX8y42I5l4vk95qy8aLpnwa', 'type': 'azure_function', 'azure_function': {'name': 'get_weather_tool', 'arguments': '{\"location\":\"New York\",\"outputqueueuri\":\"https://mmaiswcnew01prj1storage.queue.core.windows.net/azure-function-foo-output\"}', 'output': 'Weather is 8 degrees and sunny in New York'}}]}, 'usage': {'prompt_tokens': 195, 'completion_tokens': 44, 'total_tokens': 239, 'prompt_token_details': {'cached_tokens': 0}}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_steps = list(agents_client.run_steps.list(run_id=run.id, thread_id=thread.id))\n",
    "\n",
    "print(f'Nr of run step(s): {len(run_steps)}\\n')\n",
    "i=0\n",
    "for rs in run_steps:\n",
    "    i += 1\n",
    "    print(f\"Run step {i}: {rs}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfd2f9-bdc8-440d-97a7-53de7005d7c2",
   "metadata": {},
   "source": [
    "# Collect all resources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7badc6c5-afc0-4131-bbc4-47b406a71470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 agents\n",
      "1 threads\n",
      "0 files\n",
      "1 runs in 1 threads\n",
      "0 vector stores\n"
     ]
    }
   ],
   "source": [
    "all_agents = list_all_agents(client=agents_client)\n",
    "print(all_agents[\"summary\"])\n",
    "\n",
    "all_threads = list_all_threads(client=agents_client)\n",
    "print(all_threads[\"summary\"])\n",
    "\n",
    "all_files = list_all_files(client=agents_client)\n",
    "print(all_files[\"summary\"])\n",
    "\n",
    "all_runs = list_all_runs(client=agents_client)\n",
    "print(all_runs[\"summary\"])\n",
    "\n",
    "# all_runsteps=list_all_runsteps(agents_client)\n",
    "# print(all_runsteps[\"summary\"])\n",
    "\n",
    "# all_messages = list_all_messages(agents_client)\n",
    "# print(all_messages[\"summary\"])\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=agents_client)\n",
    "print(all_vectorstores[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ec759-c053-4ab7-81aa-15cfa4961468",
   "metadata": {},
   "source": [
    "# START teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b0c075-9f1a-47ca-b8c8-ad2e9d85b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Thread <thread_chQljNjcnecr2J578EFnQgWY> has been deleted\n",
      "Threads deleted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all threads\n",
    "\n",
    "i=0\n",
    "for thread in all_threads[\"content\"]:\n",
    "    i += 1\n",
    "    agents_client.threads.delete(thread_id=thread.id)\n",
    "    print(f\"{i} - Thread <{thread.id}> has been deleted\")\n",
    "\n",
    "all_threads = list_all_threads(client=agents_client)\n",
    "\n",
    "print(f\"Threads deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48399858-16e3-4b7c-a13a-aa3ed8320539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Agent <asst_oSrEExVa78HvAI1sM6Vg52yh> has been deleted\n",
      "Agents deleted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all agents\n",
    "\n",
    "i=0\n",
    "for agent in all_agents[\"content\"]:\n",
    "    i += 1\n",
    "    agents_client.delete_agent(agent_id=agent.id)\n",
    "    print(f\"{i} - Agent <{agent.id}> has been deleted\")\n",
    "\n",
    "all_agents = list_all_agents(client=agents_client)\n",
    "\n",
    "print(f\"Agents deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc2b04-a0b3-45ee-9066-4306e16511f9",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
