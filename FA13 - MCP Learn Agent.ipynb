{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n",
      "Project Endpoint: <https://aif2stdsvhdu2.services.ai.azure.com/api/projects/aif2stdwusprj01hdu2>\n",
      "azure-ai-projects library installed version: 1.0.0\n",
      "azure-ai-agents library installed version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from PIL import Image # requires pip install pillow\n",
    "from datetime import datetime\n",
    "from common.agents_helper_functions_NEW import *\n",
    "import importlib.metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if not load_dotenv(\"./../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:\n",
    "    print(\"Environment variables have been loaded ;-)\")\n",
    "\n",
    "\n",
    "project_endpoint = os.environ[\"AIF_STD_PROJECT_ENDPOINT\"]\n",
    "deployment_name =  \"gpt-4o\" # os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n",
    "api_version = \"2025-05-15-preview\" # os.environ[\"OPENAI_API_VERSION\"] # at least \"2025-04-01-preview\"\n",
    "\n",
    "print(f'Project Endpoint: <{project_endpoint}>')\n",
    "print(f\"azure-ai-projects library installed version: {importlib.metadata.version(\"azure-ai-projects\")}\")\n",
    "print(f\"azure-ai-agents library installed version: {importlib.metadata.version(\"azure-ai-agents\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Create AI Foundry Agent Client](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme?view=azure-python-preview)\n",
    "**Note**: `AIProjectClient` could be replaced by `AgentsClient`, which is easier to read. However, `Project SDK` is recommended.<br/>\n",
    "\n",
    "Anyway --> `project_client.agents == agents_client`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'McpTool' from 'azure.ai.agents.models' (D:\\ProgramData\\miniconda3\\envs\\aaas\\Lib\\site-packages\\azure\\ai\\agents\\models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m McpTool\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'McpTool' from 'azure.ai.agents.models' (D:\\ProgramData\\miniconda3\\envs\\aaas\\Lib\\site-packages\\azure\\ai\\agents\\models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import McpTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Announcing MCP Support in Azure AI Foundry Agent Service](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- [Microsoft Learn Docs MCP Server](https://github.com/MicrosoftDocs/mcp)\n",
    "- [Connect to Model Context Protocol (MCP) Servers (Preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)\n",
    "- [How to use the Model Context Protocol (MCP) tool WITH http](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples)\n",
    "- [AI Foundry Basic Agent Setup](https://github.com/azure-ai-foundry/foundry-samples/tree/main/samples/microsoft/infrastructure-setup/40-basic-agent-setup)\n",
    "- [Announcing Model Context Protocol Support (preview) in Azure AI Foundry Agent Service](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- Region: WestUS\n",
    "\n",
    "aif02westusgrp\n",
    "basicfdrydl5j\n",
    "aif02basicproject01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Agent Instructions\n",
    "agent_name = \"MCP_learn_agent\"\n",
    "\n",
    "agent_instructions = \"You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer \" \\\n",
    "\"queries about Microsoft Learn portal.\"\n",
    "\n",
    "# Question\n",
    "question = \"\"\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\n",
    "Please provide details for each model and version, highlighting the differences between versions.\n",
    "Include deprecation dates and recommended alternative versions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'mcp',\n",
       " 'server_label': 'microsoft_docs_search',\n",
       " 'server_url': 'https://learn.microsoft.com/api/mcp',\n",
       " 'allowed_tools': ['fetch_generic_documentation',\n",
       "  'search_generic_code',\n",
       "  'search_generic_documentation']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MCP Tool definition\n",
    "\n",
    "mcp_docsearch_definition = {\n",
    "    \"type\": \"mcp\", #il tool è di tipo MCP\n",
    "    \"server_label\": \"microsoft_docs_search\", #il nome univoco per MCP Server di MSLearn è \"microsoft_docs_search\"\n",
    "    \"server_url\": \"https://learn.microsoft.com/api/mcp\", #l'URL del server MCP di MSLearn\n",
    "    # \"require_approval\": \"never\" \n",
    "    \"allowed_tools\":[\"fetch_generic_documentation\", \"search_generic_code\", \"search_generic_documentation\"]\n",
    "}\n",
    "mcp_docsearch_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_MXuN4hMsXWLgnp2rJ8qui4jv',\n",
       " 'object': 'assistant',\n",
       " 'created_at': 1757695639,\n",
       " 'name': 'MCP_learn_agent',\n",
       " 'description': None,\n",
       " 'model': 'gpt-4o',\n",
       " 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.',\n",
       " 'tools': [{'type': 'mcp',\n",
       "   'server_label': 'microsoft_docs_search',\n",
       "   'server_url': 'https://learn.microsoft.com/api/mcp',\n",
       "   'allowed_tools': ['fetch_generic_documentation',\n",
       "    'search_generic_code',\n",
       "    'search_generic_documentation']}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {},\n",
       " 'metadata': {},\n",
       " 'response_format': 'auto'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_id = \"\" # ex: asst_sKeyVdFbgk5JMwCmQ0it80I6. If provided, it will be loaded rather than created\n",
    "\n",
    "if agent_id != \"\":\n",
    "    agent = project_client.agents.get_agent(agent_id=agent_id)\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=agent_name,\n",
    "        instructions=agent_instructions,\n",
    "        tools=[mcp_docsearch_definition], # leave this line commented to create a naked agent ;-)\n",
    "        tool_resources=None,\n",
    "        # headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "\n",
    "agent.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread: {'id': 'thread_esEbzz6PzW7UnRMBE2PGDMBI', 'object': 'thread', 'created_at': 1757695670, 'metadata': {}, 'tool_resources': {}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread: {thread}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message: {'id': 'msg_A91IbG5dWpX9o9aZB9cyWF9Q', 'object': 'thread.message', 'created_at': 1757695671, 'assistant_id': None, 'thread_id': 'thread_esEbzz6PzW7UnRMBE2PGDMBI', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Which Azure OpenAI models are being deprecated, and what can I use to replace them?\\nPlease provide details for each model and version, highlighting the differences between versions.\\nInclude deprecation dates and recommended alternative versions.', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "# Add a user message to the thread\n",
    "from azure.ai.agents.models import MessageRole\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=MessageRole.USER, \n",
    "    content= question\n",
    ")\n",
    "print(f\"Created message: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.FAILED\n",
      "\n",
      "Run error: {'id': 'run_HltVp3Z2uY2bCubkKBbb1rJj', 'object': 'thread.run', 'created_at': 1757695676, 'assistant_id': 'asst_MXuN4hMsXWLgnp2rJ8qui4jv', 'thread_id': 'thread_esEbzz6PzW7UnRMBE2PGDMBI', 'status': 'failed', 'started_at': 1757695677, 'expires_at': None, 'cancelled_at': None, 'failed_at': 1757695678, 'completed_at': None, 'required_action': None, 'last_error': {'code': 'server_error', 'message': 'Sorry, something went wrong.'}, 'model': 'gpt-4o', 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.', 'tools': [{'type': 'mcp', 'server_label': 'microsoft_docs_search', 'server_url': 'https://learn.microsoft.com/api/mcp', 'allowed_tools': ['fetch_generic_documentation', 'search_generic_code', 'search_generic_documentation']}], 'tool_resources': {}, 'metadata': {}, 'temperature': 1.0, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': {'prompt_tokens': 0, 'completion_tokens': 13, 'total_tokens': 13, 'prompt_token_details': {'cached_tokens': 0}}, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "# Poll the run as long as run status is queued or in progress\n",
    "while run.status in [\"queued\", \"in_progress\"]:\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")\n",
    "    time.sleep(1) # Wait for a second\n",
    "\n",
    "print()\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run error: {run}\")\n",
    "else:\n",
    "    run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    for step in run_steps:\n",
    "        print(f\"Run step: {step.id}, status: {step.status}, type: {step.type}, step: {step}\")\n",
    "        if step.type == \"tool_calls\":\n",
    "            print(f\"Tool call details:\")\n",
    "            for tool_call in step.step_details.tool_calls:\n",
    "                print(json.dumps(tool_call.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageTextContent, MessageImageFileContent, MessageTextFileCitationAnnotation, MessageTextFilePathAnnotation\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "image_files = []\n",
    "annotations = []\n",
    "citations = []\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    messages_list = list(project_client.agents.messages.list(thread_id=thread.id))  # Convert iterator to a list\n",
    "    messages_nr = len(messages_list)\n",
    "    print(f\"Here are the {messages_nr} messages:\\n\")\n",
    "    \n",
    "    for i, message in enumerate(reversed(messages_list), 1):\n",
    "        j = 0\n",
    "        print(f\"\\n===== MESSAGE {i} =====\")\n",
    "        for c in message.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageTextContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageTextContent) -->\")\n",
    "                display(Markdown(c.text.value))\n",
    "                for a in c.text.annotations:\n",
    "                    if type(a) is MessageTextFileCitationAnnotation:\n",
    "                        print(f\">>> Citation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citations.append(a)\n",
    "                    elif type(a) is MessageTextFilePathAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        annotations.append(a)\n",
    "            elif (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "                image_files.append(c.image_file.file_id)\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print annotations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Nr. of file path annotations: {len(annotations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in annotations:\n",
    "    i += 1\n",
    "    print(f\"{i} - File annotation paths: {a.text}\")\n",
    "    file_name = a.text.split('/')[-1]\n",
    "    file_id = a.file_path.file_id\n",
    "\n",
    "    #agents_client.files.save(file_id=file_id, file_name=file_name)\n",
    "    project_client.agents.files.save(file_id=file_id, file_name=file_name)\n",
    "    print(f\"\\n>>> file <{file_id}> saved as <{file_name}>\")\n",
    "    \n",
    "    # project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "    print(f\"File annotation {i} saved as file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch citations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Nr. of file path citations: {len(citations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in citations:\n",
    "    i += 1\n",
    "    print(f\"{i} - citation: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and download eventual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Nr. of image contents: {len(image_files)}\\n\")\n",
    "\n",
    "i=0\n",
    "# Generate an image file for the bar chart\n",
    "for image_file in image_files:\n",
    "    i += 1\n",
    "    print(f\"{i} - Image file id: {image_file}\")\n",
    "    file_name = f\"{image_file}.png\"\n",
    "    project_client.agents.files.save(file_id=image_file, file_name=file_name)\n",
    "    print(f\"Image content {i} file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all resources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agents = list_all_agents(client=project_client)\n",
    "print(all_agents[\"summary\"])\n",
    "\n",
    "all_threads = list_all_threads(client=project_client)\n",
    "print(all_threads[\"summary\"])\n",
    "\n",
    "all_files = list_all_files(client=project_client)\n",
    "print(all_files[\"summary\"])\n",
    "\n",
    "all_runs = list_all_runs(client=project_client)\n",
    "print(all_runs[\"summary\"])\n",
    "\n",
    "# all_runsteps=list_all_runsteps(project_client)\n",
    "# print(all_runsteps[\"summary\"])\n",
    "\n",
    "# all_messages = list_all_messages(project_client)\n",
    "# print(all_messages[\"summary\"])\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "print(all_vectorstores[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teardown for all resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all vector stores\n",
    "\n",
    "i=0\n",
    "for vector_store in all_vectorstores[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.vector_stores.delete(vector_store_id=vector_store.id)\n",
    "    print(f\"{i} - Vector store <{vector_store.id}> has been deleted\")\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "\n",
    "print(f\"Vector stores deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all files\n",
    "\n",
    "i=0\n",
    "for file in all_files['content']:\n",
    "    i += 1\n",
    "    project_client.agents.files.delete(file_id=file.id)\n",
    "    print(f\"{i} - File <{file.filename}> ({file.id}) has been deleted\")\n",
    "\n",
    "all_files = list_all_files(project_client)\n",
    "\n",
    "print(f\"Files deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all threads\n",
    "\n",
    "i=0\n",
    "for thread in all_threads[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"{i} - Thread <{thread.id}> has been deleted\")\n",
    "\n",
    "all_threads = list_all_threads(project_client)\n",
    "\n",
    "print(f\"Threads deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all agents\n",
    "\n",
    "i=0\n",
    "for agent in all_agents[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(agent_id=agent.id)\n",
    "    print(f\"{i} - Agent <{agent.id}> has been deleted\")\n",
    "\n",
    "all_agents = list_all_agents(client=project_client)\n",
    "\n",
    "print(f\"Agents deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
