{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n",
      "Project Endpoint: <https://basicfdrymlbe.services.ai.azure.com/api/projects/project>\n",
      "azure-ai-projects library installed version: 1.0.0b12\n",
      "azure-ai-agents library installed version: 1.1.0b3\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from PIL import Image # requires pip install pillow\n",
    "from datetime import datetime\n",
    "from common.agents_helper_functions_NEW import *\n",
    "import importlib.metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if not load_dotenv(\"./../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:\n",
    "    print(\"Environment variables have been loaded ;-)\")\n",
    "\n",
    "\n",
    "project_endpoint = os.environ[\"AZURE_AIFSTDEASTUS_PROJECT_ENDPOINT\"]\n",
    "deployment_name =  \"gpt-4.1\" # os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n",
    "api_version = \"2025-05-15-preview\" # os.environ[\"OPENAI_API_VERSION\"] # at least \"2025-04-01-preview\"\n",
    "\n",
    "print(f'Project Endpoint: <{project_endpoint}>')\n",
    "print(f\"azure-ai-projects library installed version: {importlib.metadata.version(\"azure-ai-projects\")}\")\n",
    "print(f\"azure-ai-agents library installed version: {importlib.metadata.version(\"azure-ai-agents\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Create AI Foundry Agent Client](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme?view=azure-python-preview)\n",
    "**Note**: `AIProjectClient` could be replaced by `AgentsClient`, which is easier to read. However, `Project SDK` is recommended.<br/>\n",
    "\n",
    "Anyway --> `project_client.agents == agents_client`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Announcing MCP Support in Azure AI Foundry Agent Service](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- [Microsoft Learn Docs MCP Server](https://github.com/MicrosoftDocs/mcp)\n",
    "- [Connect to Model Context Protocol (MCP) Servers (Preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)\n",
    "- [How to use the Model Context Protocol (MCP) tool WITH http](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples)\n",
    "- [AI Foundry Basic Agent Setup](https://github.com/azure-ai-foundry/foundry-samples/tree/main/samples/microsoft/infrastructure-setup/40-basic-agent-setup)\n",
    "- [Announcing Model Context Protocol Support (preview) in Azure AI Foundry Agent Service](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- Region: WestUS\n",
    "\n",
    "aif02westusgrp\n",
    "basicfdrydl5j\n",
    "aif02basicproject01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Agent Instructions\n",
    "agent_name = \"MCP_learn_agent\"\n",
    "\n",
    "agent_instructions = \"You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer \" \\\n",
    "\"queries about Microsoft Learn portal.\"\n",
    "\n",
    "# Question\n",
    "question = \"\"\"\n",
    "\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\n",
    "Please provide details for each model and version, highlighting the differences between versions.\n",
    "Include deprecation dates and recommended alternative versions.\n",
    "Build a final table.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'mcp',\n",
       " 'server_label': 'microsoft_docs_search',\n",
       " 'server_url': 'https://learn.microsoft.com/api/mcp',\n",
       " 'allowed_tools': ['fetch_generic_documentation',\n",
       "  'search_generic_code',\n",
       "  'search_generic_documentation']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MCP Tool definition\n",
    "\n",
    "mcp_docsearch_definition = {\n",
    "    \"type\": \"mcp\", #il tool è di tipo MCP\n",
    "    \"server_label\": \"microsoft_docs_search\", #il nome univoco per MCP Server di MSLearn è \"microsoft_docs_search\"\n",
    "    \"server_url\": \"https://learn.microsoft.com/api/mcp\", #l'URL del server MCP di MSLearn\n",
    "    # \"require_approval\": \"never\" \n",
    "    \"allowed_tools\":[\"fetch_generic_documentation\", \"search_generic_code\", \"search_generic_documentation\"]\n",
    "}\n",
    "mcp_docsearch_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent creation\n",
    "Should be similar to this:\n",
    "```\n",
    "{'id': 'asst_sKeyVdFbgk5JMwCmQ0it80I6',\n",
    " 'object': 'assistant',\n",
    " 'created_at': 1751492588,\n",
    " 'name': 'MCP_learn_agent',\n",
    " 'description': None,\n",
    " 'model': 'gpt-4.1',\n",
    " 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.',\n",
    " 'tools': [{'type': 'mcp',\n",
    "   'server_label': 'microsoft_docs_search',\n",
    "   'server_url': 'https://learn.microsoft.com/api/mcp',\n",
    "   'allowed_tools': ['fetch_generic_documentation',\n",
    "    'search_generic_code',\n",
    "    'search_generic_documentation']}],\n",
    " 'top_p': 1.0,\n",
    " 'temperature': 1.0,\n",
    " 'tool_resources': {},\n",
    " 'metadata': {},\n",
    " 'response_format': 'auto'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_p3bSr5gZk6Jn9JjWSEsi2Ttj',\n",
       " 'object': 'assistant',\n",
       " 'created_at': 1751496497,\n",
       " 'name': 'MCP_learn_agent',\n",
       " 'description': None,\n",
       " 'model': 'gpt-4.1',\n",
       " 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.',\n",
       " 'tools': [{'type': 'mcp',\n",
       "   'server_label': 'microsoft_docs_search',\n",
       "   'server_url': 'https://learn.microsoft.com/api/mcp',\n",
       "   'allowed_tools': ['fetch_generic_documentation',\n",
       "    'search_generic_code',\n",
       "    'search_generic_documentation']}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {},\n",
       " 'metadata': {},\n",
       " 'response_format': 'auto'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_id = \"\" # ex: asst_sKeyVdFbgk5JMwCmQ0it80I6. If provided, it will be loaded rather than created\n",
    "\n",
    "if agent_id != \"\":\n",
    "    agent = project_client.agents.get_agent(agent_id=agent_id)\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=agent_name,\n",
    "        instructions=agent_instructions,\n",
    "        tools=[mcp_docsearch_definition], # leave this line commented to create a naked agent ;-)\n",
    "        tool_resources=None,\n",
    "        # headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "\n",
    "agent.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread: {'id': 'thread_iuqiFulWfA7TxPIrz5NiOw16', 'object': 'thread', 'created_at': 1751496497, 'metadata': {}, 'tool_resources': {}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread: {thread}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message: {'id': 'msg_v8NFYYIh8hMtD1xqLkkREK1S', 'object': 'thread.message', 'created_at': 1751496498, 'assistant_id': None, 'thread_id': 'thread_iuqiFulWfA7TxPIrz5NiOw16', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': '\\n\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\\nPlease provide details for each model and version, highlighting the differences between versions.\\nInclude deprecation dates and recommended alternative versions.\\nBuild a final table.\\n', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "# Add a user message to the thread\n",
    "from azure.ai.agents.models import MessageRole\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=MessageRole.USER, \n",
    "    content= question\n",
    ")\n",
    "print(f\"Created message: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "# Poll the run as long as run status is queued or in progress\n",
    "while run.status in [\"queued\", \"in_progress\"]:\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")\n",
    "    time.sleep(1) # Wait for a second\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run error: {run}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 2 messages:\n",
      "\n",
      "\n",
      "===== MESSAGE 1 =====\n",
      "\n",
      "Message 1 / CONTENT 1 (MessageTextContent) --> Text: \n",
      "\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\n",
      "Please provide details for each model and version, highlighting the differences between versions.\n",
      "Include deprecation dates and recommended alternative versions.\n",
      "Build a final table.\n",
      "\n",
      "\n",
      "===== MESSAGE 2 =====\n",
      "\n",
      "Message 2 / CONTENT 1 (MessageTextContent) --> Text: I couldn't directly access the latest documentation right now due to a temporary technical issue. However, I can provide an overview based on current, widely available information about Azure OpenAI models' deprecation, replacements, and their differences. \n",
      "\n",
      "Here’s how the deprecation of Azure OpenAI models typically proceeds:\n",
      "\n",
      "---\n",
      "### Common Deprecated Models in Azure OpenAI\n",
      "\n",
      "| Deprecated Model         | Version   | Deprecation Date        | Recommended Replacement   | Key Differences                                                   |\n",
      "|-------------------------|-----------|-------------------------|---------------------------|--------------------------------------------------------------------|\n",
      "| GPT-3 (Davinci, Curie)  | v1        | March 1, 2024           | GPT-3.5, GPT-4            | GPT-3.5 & GPT-4 offer better reasoning, coding, and efficiency     |\n",
      "| Codex (code-davinci-002)| v1        | January 2024            | GPT-3.5 Turbo, GPT-4      | GPT-3.5 Turbo outperforms Codex on code completion and instructions|\n",
      "| GPT-3 (ada, babbage)    | v1        | March 1, 2024           | GPT-3.5 Turbo, GPT-4      | Improved output quality, lower latency, better cost/performance    |\n",
      "| Text-Davinci-003        | v1        | January 13, 2024        | GPT-3.5 Turbo             | GPT-3.5 Turbo is faster, supports function calls, more capable     |\n",
      "\n",
      "---\n",
      "\n",
      "### Key Points:\n",
      "\n",
      "- OpenAI and Azure are gradually deprecating older GPT-3 and Codex models.\n",
      "- The recommended alternatives are newer versions like GPT-3.5 Turbo and GPT-4 models.\n",
      "- Deprecation dates can vary but are typically communicated months in advance.\n",
      "- Differences between versions generally include: improved performance, lower latency, enhanced reasoning, and better cost efficiency.\n",
      "\n",
      "---\n",
      "\n",
      "### Sample Table\n",
      "\n",
      "| Deprecated Model   | Version | Deprecation Date | Replacement/Available Model | Differences/Improvements                                    |\n",
      "|--------------------|---------|------------------|----------------------------|-------------------------------------------------------------|\n",
      "| text-davinci-002   | v1      | March 1, 2024    | gpt-3.5-turbo, gpt-4       | Faster, more accurate, more cost-effective                   |\n",
      "| code-davinci-002   | v1      | Jan 2024         | gpt-3.5-turbo              | Better code following, completion, and function calls        |\n",
      "| text-ada-001       | v1      | March 1, 2024    | gpt-3.5-turbo, gpt-4       | Improved reliability, output quality, and performance        |\n",
      "| curie              | v1      | March 1, 2024    | gpt-3.5-turbo, gpt-4       | More capable, better at following instructions               |\n",
      "\n",
      "---\n",
      "\n",
      "For the most up-to-date and detailed list (including any new model updates or last-minute extension to deadlines), please visit the official Azure OpenAI documentation:\n",
      "- [Azure OpenAI Service Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/)\n",
      "\n",
      "Would you like specific guidance on migrating your workloads or implementation samples for the newer models?\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import MessageTextContent, MessageImageFileContent, MessageTextFileCitationAnnotation, MessageTextFilePathAnnotation\n",
    "\n",
    "image_files = []\n",
    "annotations = []\n",
    "citations = []\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    messages_list = list(project_client.agents.messages.list(thread_id=thread.id))  # Convert iterator to a list\n",
    "    messages_nr = len(messages_list)\n",
    "    print(f\"Here are the {messages_nr} messages:\\n\")\n",
    "    \n",
    "    for i, message in enumerate(reversed(messages_list), 1):\n",
    "        j = 0\n",
    "        print(f\"\\n===== MESSAGE {i} =====\")\n",
    "        for c in message.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageTextContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    if type(a) is MessageTextFileCitationAnnotation:\n",
    "                        print(f\">>> Citation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citations.append(a)\n",
    "                    elif type(a) is MessageTextFilePathAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        annotations.append(a)\n",
    "            elif (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "                image_files.append(c.image_file.file_id)\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print annotations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of file path annotations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Nr. of file path annotations: {len(annotations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in annotations:\n",
    "    i += 1\n",
    "    print(f\"{i} - File annotation paths: {a.text}\")\n",
    "    file_name = a.text.split('/')[-1]\n",
    "    file_id = a.file_path.file_id\n",
    "\n",
    "    #agents_client.files.save(file_id=file_id, file_name=file_name)\n",
    "    project_client.agents.files.save(file_id=file_id, file_name=file_name)\n",
    "    print(f\"\\n>>> file <{file_id}> saved as <{file_name}>\")\n",
    "    \n",
    "    # project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "    print(f\"File annotation {i} saved as file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch citations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of file path citations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Nr. of file path citations: {len(citations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in citations:\n",
    "    i += 1\n",
    "    print(f\"{i} - citation: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and download eventual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of image contents: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Nr. of image contents: {len(image_files)}\\n\")\n",
    "\n",
    "i=0\n",
    "# Generate an image file for the bar chart\n",
    "for image_file in image_files:\n",
    "    i += 1\n",
    "    print(f\"{i} - Image file id: {image_file}\")\n",
    "    file_name = f\"{image_file}.png\"\n",
    "    project_client.agents.files.save(file_id=image_file, file_name=file_name)\n",
    "    print(f\"Image content {i} file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all resources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 agents\n",
      "1 threads\n",
      "0 files\n",
      "1 runs in 1 threads\n",
      "0 vector stores\n"
     ]
    }
   ],
   "source": [
    "all_agents = list_all_agents(client=project_client)\n",
    "print(all_agents[\"summary\"])\n",
    "\n",
    "all_threads = list_all_threads(client=project_client)\n",
    "print(all_threads[\"summary\"])\n",
    "\n",
    "all_files = list_all_files(client=project_client)\n",
    "print(all_files[\"summary\"])\n",
    "\n",
    "all_runs = list_all_runs(client=project_client)\n",
    "print(all_runs[\"summary\"])\n",
    "\n",
    "# all_runsteps=list_all_runsteps(project_client)\n",
    "# print(all_runsteps[\"summary\"])\n",
    "\n",
    "# all_messages = list_all_messages(project_client)\n",
    "# print(all_messages[\"summary\"])\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "print(all_vectorstores[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teardown for all resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector stores deleted: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all vector stores\n",
    "\n",
    "i=0\n",
    "for vector_store in all_vectorstores[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.vector_stores.delete(vector_store_id=vector_store.id)\n",
    "    print(f\"{i} - Vector store <{vector_store.id}> has been deleted\")\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "\n",
    "print(f\"Vector stores deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files deleted: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all files\n",
    "\n",
    "i=0\n",
    "for file in all_files['content']:\n",
    "    i += 1\n",
    "    project_client.agents.files.delete(file_id=file.id)\n",
    "    print(f\"{i} - File <{file.filename}> ({file.id}) has been deleted\")\n",
    "\n",
    "all_files = list_all_files(project_client)\n",
    "\n",
    "print(f\"Files deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Thread <thread_iuqiFulWfA7TxPIrz5NiOw16> has been deleted\n",
      "Threads deleted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all threads\n",
    "\n",
    "i=0\n",
    "for thread in all_threads[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"{i} - Thread <{thread.id}> has been deleted\")\n",
    "\n",
    "all_threads = list_all_threads(project_client)\n",
    "\n",
    "print(f\"Threads deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Agent <asst_p3bSr5gZk6Jn9JjWSEsi2Ttj> has been deleted\n",
      "Agents deleted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all agents\n",
    "\n",
    "i=0\n",
    "for agent in all_agents[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(agent_id=agent.id)\n",
    "    print(f\"{i} - Agent <{agent.id}> has been deleted\")\n",
    "\n",
    "all_agents = list_all_agents(client=project_client)\n",
    "\n",
    "print(f\"Agents deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
