{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n",
      "Project Endpoint: <https://basicfdrymlbe.services.ai.azure.com/api/projects/project>\n",
      "azure-ai-projects library installed version: 1.0.0b12\n",
      "azure-ai-agents library installed version: 1.1.0b3\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from PIL import Image # requires pip install pillow\n",
    "from datetime import datetime\n",
    "from common.agents_helper_functions_NEW import *\n",
    "import importlib.metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if not load_dotenv(\"./../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:\n",
    "    print(\"Environment variables have been loaded ;-)\")\n",
    "\n",
    "\n",
    "project_endpoint = os.environ[\"AZURE_AIFSTDEASTUS_PROJECT_ENDPOINT\"]\n",
    "deployment_name =  \"gpt-4.1\" # os.environ[\"MODEL_DEPLOYMENT_NAME\"] # \n",
    "api_version = os.environ[\"OPENAI_API_VERSION\"] # at least \"2025-04-01-preview\"\n",
    "\n",
    "print(f'Project Endpoint: <{project_endpoint}>')\n",
    "print(f\"azure-ai-projects library installed version: {importlib.metadata.version(\"azure-ai-projects\")}\")\n",
    "print(f\"azure-ai-agents library installed version: {importlib.metadata.version(\"azure-ai-agents\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Create AI Foundry Agent Client](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme?view=azure-python-preview)\n",
    "**Note**: I could create the `project` client rather than the `agent` client, however this is easier to read.<br/>\n",
    "Please consider that `project_client.agens == agents_client`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.agents._patch.AgentsClient at 0x1b8d9416f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "agents_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MCP Agent](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- [Connect to Model Context Protocol (MCP) Servers (Preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)\n",
    "- [How to use the Model Context Protocol (MCP) tool WITH http](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples)\n",
    "- [AI Foundry Basic Agent Setup](https://github.com/azure-ai-foundry/foundry-samples/tree/main/samples/microsoft/infrastructure-setup/40-basic-agent-setup)\n",
    "- [Announcing Model Context Protocol Support (preview) in Azure AI Foundry Agent Service](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- Region: WestUS\n",
    "\n",
    "aif02westusgrp\n",
    "basicfdrydl5j\n",
    "aif02basicproject01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Agent Instructions\n",
    "agent_name = \"MCP_learn_agent\"\n",
    "\n",
    "agent_instructions = \"You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer \" \\\n",
    "\"queries about Microsoft Learn portal.\"\n",
    "\n",
    "# Question\n",
    "question = \"\"\"\n",
    "\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\n",
    "Please provide details for each model and version, highlighting the differences between versions.\n",
    "Include deprecation dates and recommended alternative versions.\n",
    "Build a final table.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'mcp',\n",
       " 'server_label': 'microsoft_docs_search',\n",
       " 'server_url': 'https://learn.microsoft.com/api/mcp',\n",
       " 'allowed_tools': ['fetch_generic_documentation',\n",
       "  'search_generic_code',\n",
       "  'search_generic_documentation']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MCP Tool definition\n",
    "\n",
    "mcp_tool_definition = {\n",
    "    \"type\": \"mcp\", #il tool è di tipo MCP\n",
    "    \"server_label\": \"microsoft_docs_search\", #il nome univoco per MCP Server di MSLearn è \"microsoft_docs_search\"\n",
    "    \"server_url\": \"https://learn.microsoft.com/api/mcp\", #l'URL del server MCP di MSLearn\n",
    "    # \"require_approval\": \"never\" \n",
    "    \"allowed_tools\":[\"fetch_generic_documentation\", \"search_generic_code\", \"search_generic_documentation\"]\n",
    "}\n",
    "mcp_tool_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_YSuLw2c9qKXdNqkngW7fR2wq',\n",
       " 'object': 'assistant',\n",
       " 'created_at': 1751492292,\n",
       " 'name': 'MCP_learn_agent',\n",
       " 'description': None,\n",
       " 'model': 'gpt-4.1',\n",
       " 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.',\n",
       " 'tools': [{'type': 'mcp',\n",
       "   'server_label': 'microsoft_docs_search',\n",
       "   'server_url': 'https://learn.microsoft.com/api/mcp',\n",
       "   'allowed_tools': ['fetch_generic_documentation',\n",
       "    'search_generic_code',\n",
       "    'search_generic_documentation']}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {},\n",
       " 'metadata': {},\n",
       " 'response_format': 'auto'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_id = \"\" # ex: asst_j1qWBdGsjbK4hHcO0M0n3M5p. If provided, it will be loaded rather than created\n",
    "\n",
    "if agent_id != \"\":\n",
    "    agent = agents_client.get_agent(agent_id=agent_id)\n",
    "else:\n",
    "    agent = agents_client.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=agent_name,\n",
    "        instructions=agent_instructions,\n",
    "        tools=[mcp_tool_definition], # leave this line commented to create a naked agent ;-)\n",
    "        tool_resources=None,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "\n",
    "agent.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread: {'id': 'thread_VjPAXB9kC9C2xKoR43Tj2qEc', 'object': 'thread', 'created_at': 1751492292, 'metadata': {}, 'tool_resources': {}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = agents_client.threads.create()\n",
    "print(f\"Created thread: {thread}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message: {'id': 'msg_PJan5C3TBSn6k85OzW3AkiOX', 'object': 'thread.message', 'created_at': 1751492293, 'assistant_id': None, 'thread_id': 'thread_VjPAXB9kC9C2xKoR43Tj2qEc', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': '\\n\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\\nPlease provide details for each model and version, highlighting the differences between versions.\\nInclude deprecation dates and recommended alternative versions.\\nBuild a final table.\\n', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "# Add a user message to the thread\n",
    "from azure.ai.agents.models import MessageRole\n",
    "\n",
    "message = agents_client.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=MessageRole.USER, \n",
    "    content= question\n",
    ")\n",
    "print(f\"Created message: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED.\n",
      "\n",
      "Run: {'id': 'run_o7ad2kBaxfZpEM7bntQVuBPF', 'object': 'thread.run', 'created_at': 1751492294, 'assistant_id': 'asst_YSuLw2c9qKXdNqkngW7fR2wq', 'thread_id': 'thread_VjPAXB9kC9C2xKoR43Tj2qEc', 'status': 'completed', 'started_at': 1751492294, 'expires_at': None, 'cancelled_at': None, 'failed_at': None, 'completed_at': 1751492303, 'required_action': None, 'last_error': None, 'model': 'gpt-4.1', 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.', 'tools': [{'type': 'mcp', 'server_label': 'microsoft_docs_search', 'server_url': 'https://learn.microsoft.com/api/mcp', 'allowed_tools': ['fetch_generic_documentation', 'search_generic_code', 'search_generic_documentation']}], 'tool_resources': {}, 'metadata': {}, 'temperature': 1.0, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': {'prompt_tokens': 307, 'completion_tokens': 764, 'total_tokens': 1071, 'prompt_token_details': {'cached_tokens': 0}}, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run the agent\n",
    "run = agents_client.runs.create_and_process\\\n",
    "    (thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}.\\n\\nRun: {run}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 2 messages:\n",
      "\n",
      "\n",
      "===== MESSAGE 1 =====\n",
      "\n",
      "Message 1 / CONTENT 1 (MessageTextContent) --> Text: \n",
      "\"Which Azure OpenAI models are being deprecated, and what can I use to replace them?\n",
      "Please provide details for each model and version, highlighting the differences between versions.\n",
      "Include deprecation dates and recommended alternative versions.\n",
      "Build a final table.\n",
      "\n",
      "\n",
      "===== MESSAGE 2 =====\n",
      "\n",
      "Message 2 / CONTENT 1 (MessageTextContent) --> Text: I’m currently unable to access the most recent documentation directly, but I can provide an overview based on existing knowledge about Azure OpenAI models deprecation, as well as general guidance. For the most accurate and detailed information, always refer to the official Azure OpenAI Service documentation.\n",
      "\n",
      "### General Model Deprecations (as of early 2024)\n",
      "\n",
      "#### GPT-3 and Early GPT-3.5 Models\n",
      "- **Deprecated Models:**\n",
      "  - `text-davinci-003`\n",
      "  - `text-ada-001`, `text-babbage-001`, `text-curie-001`, etc.\n",
      "- **Deprecation Dates:** \n",
      "  - Most legacy GPT-3 models (like `text-davinci-003`) are deprecated or scheduled for retirement throughout 2023 and 2024.\n",
      "- **Recommended Alternatives:**\n",
      "  - `gpt-3.5-turbo`\n",
      "  - `gpt-4`, `gpt-4-turbo` (most recent and capable)\n",
      "- **Key Differences:**\n",
      "  - GPT-4 models provide better reasoning, less hallucination, and improved context length.\n",
      "  - Higher capability, broader multilingual support, and better instruction following.\n",
      "\n",
      "#### Embedding Models\n",
      "- **Deprecated Models:**\n",
      "  - `text-embedding-ada-002` (earlier embeddings are already deprecated)\n",
      "- **Deprecation Dates:** \n",
      "  - Older embedding models deprecated earlier; check specific documentation for up-to-date status.\n",
      "- **Recommended Alternatives:**\n",
      "  - Use latest `text-embedding-ada-002` or newer series.\n",
      "- **Key Differences:**\n",
      "  - Improved vector representation, supporting broader use cases and larger contexts.\n",
      "\n",
      "#### Codex Models\n",
      "- **Deprecated Models:**\n",
      "  - `code-davinci-002`\n",
      "- **Deprecation Dates:**\n",
      "  - Codex models are typically being retired as GPT-4 supports code much better.\n",
      "- **Recommended Alternatives:**\n",
      "  - Use `gpt-4` or `gpt-3.5-turbo` for code completion.\n",
      "- **Key Differences:**\n",
      "  - Better capability in generating, explaining, and debugging code.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary Table\n",
      "\n",
      "| Deprecated Model           | Deprecation Date    | Recommended Alternative      | Key Differences                                             |\n",
      "|----------------------------|--------------------|-----------------------------|------------------------------------------------------------|\n",
      "| text-davinci-003           | 2023-2024*         | gpt-3.5-turbo, gpt-4        | Higher accuracy, capacity, context, and instruction following|\n",
      "| text-embedding-ada-001     | Deprecated earlier | text-embedding-ada-002      | More robust and richer embeddings                           |\n",
      "| code-davinci-002           | 2023-2024*         | gpt-4, gpt-3.5-turbo        | Better for code tasks, improved reasoning                   |\n",
      "| Other GPT-3 base models    | 2023-2024*         | gpt-3.5-turbo, gpt-4        | Same as above                                               |\n",
      "\n",
      "\\* Actual deprecation dates may vary. Always check latest documentation or your Azure OpenAI Portal for up-to-date timeline and model availability.\n",
      "\n",
      "---\n",
      "\n",
      "If you need model-specific status for your subscription or more technical migration details, please visit the official Azure OpenAI Service [Model lifecycle page](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models) or reach out through your Azure support channel. Would you like me to assist you with a direct link or further migration guidance?\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import MessageTextContent, MessageImageFileContent, MessageTextFileCitationAnnotation, MessageTextFilePathAnnotation\n",
    "\n",
    "image_files = []\n",
    "annotations = []\n",
    "citations = []\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = agents_client.messages.list(thread_id=thread.id)\n",
    "    messages_list = list(agents_client.messages.list(thread_id=thread.id))  # Convert iterator to a list\n",
    "    messages_nr = len(messages_list)\n",
    "    print(f\"Here are the {messages_nr} messages:\\n\")\n",
    "    \n",
    "    for i, message in enumerate(reversed(messages_list), 1):\n",
    "        j = 0\n",
    "        print(f\"\\n===== MESSAGE {i} =====\")\n",
    "        for c in message.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageTextContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    if type(a) is MessageTextFileCitationAnnotation:\n",
    "                        print(f\">>> Citation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citations.append(a)\n",
    "                    elif type(a) is MessageTextFilePathAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        annotations.append(a)\n",
    "            elif (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "                image_files.append(c.image_file.file_id)\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print annotations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of file path annotations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Nr. of file path annotations: {len(annotations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in annotations:\n",
    "    i += 1\n",
    "    print(f\"{i} - File annotation paths: {a.text}\")\n",
    "    file_name = a.text.split('/')[-1]\n",
    "    file_id = a.file_path.file_id\n",
    "\n",
    "    #agents_client.files.save(file_id=file_id, file_name=file_name)\n",
    "    project_client.agents.files.save(file_id=file_id, file_name=file_name)\n",
    "    print(f\"\\n>>> file <{file_id}> saved as <{file_name}>\")\n",
    "    \n",
    "    # project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "    print(f\"File annotation {i} saved as file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch citations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of file path citations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Nr. of file path citations: {len(citations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in citations:\n",
    "    i += 1\n",
    "    print(f\"{i} - citation: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and download eventual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. of image contents: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"Nr. of image contents: {len(image_files)}\\n\")\n",
    "\n",
    "i=0\n",
    "# Generate an image file for the bar chart\n",
    "for image_file in image_files:\n",
    "    i += 1\n",
    "    print(f\"{i} - Image file id: {image_file}\")\n",
    "    file_name = f\"{image_file}.png\"\n",
    "    project_client.agents.files.save(file_id=image_file, file_name=file_name)\n",
    "    print(f\"Image content {i} file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all resources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 agents\n",
      "1 threads\n",
      "0 files\n",
      "1 runs in 1 threads\n",
      "0 vector stores\n"
     ]
    }
   ],
   "source": [
    "all_agents = list_all_agents(client=agents_client)\n",
    "print(all_agents[\"summary\"])\n",
    "\n",
    "all_threads = list_all_threads(client=agents_client)\n",
    "print(all_threads[\"summary\"])\n",
    "\n",
    "all_files = list_all_files(client=agents_client)\n",
    "print(all_files[\"summary\"])\n",
    "\n",
    "all_runs = list_all_runs(client=agents_client)\n",
    "print(all_runs[\"summary\"])\n",
    "\n",
    "# all_runsteps=list_all_runsteps(agents_client)\n",
    "# print(all_runsteps[\"summary\"])\n",
    "\n",
    "# all_messages = list_all_messages(agents_client)\n",
    "# print(all_messages[\"summary\"])\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=agents_client)\n",
    "print(all_vectorstores[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teardown for all resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector stores deleted: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all vector stores\n",
    "\n",
    "i=0\n",
    "for vector_store in all_vectorstores[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.vector_stores.delete(vector_store_id=vector_store.id)\n",
    "    print(f\"{i} - Vector store <{vector_store.id}> has been deleted\")\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=agents_client)\n",
    "\n",
    "print(f\"Vector stores deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files deleted: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all files\n",
    "\n",
    "i=0\n",
    "for file in all_files['content']:\n",
    "    i += 1\n",
    "    agents_client.files.delete(file_id=file.id)\n",
    "    print(f\"{i} - File <{file.filename}> ({file.id}) has been deleted\")\n",
    "\n",
    "all_files = list_all_files(agents_client)\n",
    "\n",
    "print(f\"Files deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Thread <thread_VjPAXB9kC9C2xKoR43Tj2qEc> has been deleted\n",
      "Threads deleted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all threads\n",
    "\n",
    "i=0\n",
    "for thread in all_threads[\"content\"]:\n",
    "    i += 1\n",
    "    agents_client.threads.delete(thread_id=thread.id)\n",
    "    print(f\"{i} - Thread <{thread.id}> has been deleted\")\n",
    "\n",
    "all_threads = list_all_threads(agents_client)\n",
    "\n",
    "print(f\"Threads deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Agent <asst_YSuLw2c9qKXdNqkngW7fR2wq> has been deleted\n",
      "Agents deleted: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete all agents\n",
    "\n",
    "i=0\n",
    "for agent in all_agents[\"content\"]:\n",
    "    i += 1\n",
    "    agents_client.delete_agent(agent_id=agent.id)\n",
    "    print(f\"{i} - Agent <{agent.id}> has been deleted\")\n",
    "\n",
    "all_agents = list_all_agents(client=agents_client)\n",
    "\n",
    "print(f\"Agents deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
