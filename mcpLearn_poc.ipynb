{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n",
      "Project Endpoint: <https://basicfdrymlbe.services.ai.azure.com/api/projects/project>\n",
      "azure-ai-projects library installed version: 1.0.0b12\n",
      "azure-ai-agents library installed version: 1.1.0b2\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from PIL import Image # requires pip install pillow\n",
    "from datetime import datetime\n",
    "from common.agents_helper_functions_NEW import *\n",
    "import importlib.metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if not load_dotenv(\"./../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:\n",
    "    print(\"Environment variables have been loaded ;-)\")\n",
    "\n",
    "\n",
    "project_endpoint = os.environ[\"AZURE_AIFSTDEASTUS_PROJECT_ENDPOINT\"]\n",
    "deployment_name =  os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n",
    "api_version = \"2025-05-15-preview\" # os.environ[\"OPENAI_API_VERSION\"] # at least \"2025-03-01-preview\"\n",
    "\n",
    "print(f'Project Endpoint: <{project_endpoint}>')\n",
    "print(f\"azure-ai-projects library installed version: {importlib.metadata.version(\"azure-ai-projects\")}\")\n",
    "print(f\"azure-ai-agents library installed version: {importlib.metadata.version(\"azure-ai-agents\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Create AI Foundry Agent Client](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme?view=azure-python-preview)\n",
    "**Note**: I could create the `project` client rather than the `agent` client, however this is easier to read.<br/>\n",
    "Please consider that `project_client.agens == agents_client`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.projects._patch.AIProjectClient at 0x7bc3a41ad6a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "project_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MCP Agent](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- [Connect to Model Context Protocol (MCP) Servers (Preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)\n",
    "- [How to use the Model Context Protocol (MCP) tool WITH http](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples)\n",
    "- [AI Foundry Basic Agent Setup](https://github.com/azure-ai-foundry/foundry-samples/tree/main/samples/microsoft/infrastructure-setup/40-basic-agent-setup)\n",
    "- [Announcing Model Context Protocol Support (preview) in Azure AI Foundry Agent Service](https://devblogs.microsoft.com/foundry/announcing-model-context-protocol-support-preview-in-azure-ai-foundry-agent-service/)\n",
    "- Region: WestUS\n",
    "\n",
    "aif02westusgrp\n",
    "basicfdrydl5j\n",
    "aif02basicproject01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Agent Instructions\n",
    "agent_name = \"MCP_learn_agent\"\n",
    "\n",
    "agent_instructions = \"You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer \" \\\n",
    "\"queries about Microsoft Learn portal.\"\n",
    "\n",
    "# Question\n",
    "question = \"Quali sono i modelli Azure OpenAI in scadenza e con cosa posso sostituirli? \" \\\n",
    "\"Fornisci dettagli per ogni modello e versione, evidenziando le differenze tra le versioni. \" \\\n",
    "\"Includi anche le date di scadenza e le versioni alternative consigliate.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Tool definition\n",
    "\n",
    "mcp_tool_definition = {\n",
    "    \"type\": \"mcp\", #il tool è di tipo MCP\n",
    "    \"server_label\": \"microsoft_docs_search\", #il nome univoco per MCP Server di MSLearn è \"microsoft_docs_search\"\n",
    "    \"server_url\": \"https://learn.microsoft.com/api/mcp\", #l'URL del server MCP di MSLearn\n",
    "    # \"require_approval\": \"never\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(unknown_parameter) Unknown parameter: 'tools[0].approval'.\nCode: unknown_parameter\nMessage: Unknown parameter: 'tools[0].approval'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     agent = project_client.agents.get_agent(assistant_id=assistant_id)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     agent = \u001b[43mproject_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmcp_tool_definition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# leave this line commented to create a naked agent ;-)\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx-ms-enable-preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m agent.as_dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/anaconda/envs/aaas/lib/python3.13/site-packages/azure/core/tracing/decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/anaconda/envs/aaas/lib/python3.13/site-packages/azure/ai/agents/_patch.py:294\u001b[39m, in \u001b[36mAgentsClient.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, toolset, temperature, top_p, response_format, metadata, content_type, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     tools = toolset.definitions\n\u001b[32m    292\u001b[39m     tool_resources = toolset.resources\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m new_agent = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_agent\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/anaconda/envs/aaas/lib/python3.13/site-packages/azure/core/tracing/decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/anaconda/envs/aaas/lib/python3.13/site-packages/azure/ai/agents/operations/_operations.py:5310\u001b[39m, in \u001b[36mAgentsClientOperationsMixin.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, temperature, top_p, response_format, metadata, **kwargs)\u001b[39m\n\u001b[32m   5308\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m   5309\u001b[39m     error = _failsafe_deserialize(_models.AgentV1Error, response.json())\n\u001b[32m-> \u001b[39m\u001b[32m5310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n\u001b[32m   5312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[32m   5313\u001b[39m     deserialized = response.iter_bytes()\n",
      "\u001b[31mHttpResponseError\u001b[39m: (unknown_parameter) Unknown parameter: 'tools[0].approval'.\nCode: unknown_parameter\nMessage: Unknown parameter: 'tools[0].approval'."
     ]
    }
   ],
   "source": [
    "# Agent creation\n",
    "\n",
    "assistant_id = \"\" # ex: asst_j1qWBdGsjbK4hHcO0M0n3M5p. If provided, it will be loaded rather than created\n",
    "\n",
    "if assistant_id != \"\":\n",
    "    agent = project_client.agents.get_agent(assistant_id=assistant_id)\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=agent_name,\n",
    "        instructions=agent_instructions,\n",
    "        tools=[mcp_tool_definition], # leave this line commented to create a naked agent ;-)\n",
    "        tool_resources=None,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "\n",
    "agent.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the thread and attach a new message to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread: {'id': 'thread_M7JWwNMqn9JB5Eer2TVjI6P3', 'object': 'thread', 'created_at': 1751467171, 'metadata': {}, 'tool_resources': {}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread: {thread}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message: {'id': 'msg_9J3zCpBEQ2gx1LmE5JbUNWtw', 'object': 'thread.message', 'created_at': 1751467171, 'assistant_id': None, 'thread_id': 'thread_M7JWwNMqn9JB5Eer2TVjI6P3', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Quali sono i modelli Azure OpenAI in scadenza e con cosa posso sostituirli? Fornisci dettagli per ogni modello e versione, evidenziando le differenze tra le versioni. Includi anche le date di scadenza e le versioni alternative consigliate.', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "# Add a user message to the thread\n",
    "from azure.ai.agents.models import MessageRole\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=MessageRole.USER, \n",
    "    content= question\n",
    ")\n",
    "print(f\"Created message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_Xprmz5JfihjrcRwRcnYZqGWT', 'object': 'thread.run', 'created_at': 1751467221, 'assistant_id': 'asst_63fy6vYue8aNd6OEBFQcwL1W', 'thread_id': 'thread_M7JWwNMqn9JB5Eer2TVjI6P3', 'status': 'requires_action', 'started_at': 1751467221, 'expires_at': 1751503221, 'cancelled_at': None, 'failed_at': None, 'completed_at': None, 'required_action': {'type': 'submit_tool_approval', 'submit_tool_approval': {'tool_calls': [{'id': 'call_90ouH8Uw62XcDppIte9bYynH', 'type': 'mcp', 'arguments': '{\"question\":\"Quali sono i modelli Azure OpenAI in scadenza e con cosa posso sostituirli? Fornisci dettagli per ogni modello e versione, evidenziando le differenze tra le versioni. Includi anche le date di scadenza e le versioni alternative consigliate.\"}', 'name': 'microsoft_docs_search', 'server_label': 'microsoft_docs_search'}]}}, 'last_error': None, 'model': 'gpt-4o', 'instructions': 'You are a customer support chatbot. Use the tools provided and your knowledge base to best respond to customer queries about Microsoft Learn portal.', 'tools': [{'type': 'mcp', 'server_label': 'microsoft_docs_search', 'server_url': 'https://learn.microsoft.com/api/mcp', 'allowed_tools': None}], 'tool_resources': {}, 'metadata': {}, 'temperature': 1.0, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': None, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run =  project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n",
      "Run status: RunStatus.REQUIRES_ACTION\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Poll the run as long as run status is queued or in progress\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m run.status \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mqueued\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33min_progress\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrequires_action\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Wait for a second\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Poll the run as long as run status is queued or in progress\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    # Wait for a second\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run error: {run.last_error}\")\n",
    "\n",
    "run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "for step in run_steps:\n",
    "    print(f\"Run step: {step.id}, status: {step.status}, type: {step.type}\")\n",
    "    if step.type == \"tool_calls\":\n",
    "        print(f\"Tool call details:\")\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            print(json.dumps(tool_call.as_dict(), indent=2))\n",
    "\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "for data_point in messages:\n",
    "    last_message_content = data_point.content[-1]\n",
    "    if isinstance(last_message_content, MessageTextContent):\n",
    "        print(f\"{data_point.role}: {last_message_content.text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the agent syncrhonously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run the agent\n",
    "run = project_client.agents.runs.create_and_process\\\n",
    "    (thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}.\\n\\nRun: {run}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch messages from the thread after the agent run execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageTextContent, MessageImageFileContent, MessageTextFileCitationAnnotation, MessageTextFilePathAnnotation\n",
    "\n",
    "image_files = []\n",
    "annotations = []\n",
    "citations = []\n",
    "\n",
    "if run.status == 'completed':\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    messages_list = list(project_client.agents.messages.list(thread_id=thread.id))  # Convert iterator to a list\n",
    "    messages_nr = len(messages_list)\n",
    "    print(f\"Here are the {messages_nr} messages:\\n\")\n",
    "    \n",
    "    for i, message in enumerate(reversed(messages_list), 1):\n",
    "        j = 0\n",
    "        print(f\"\\n===== MESSAGE {i} =====\")\n",
    "        for c in message.content:\n",
    "            j +=1\n",
    "            if (type(c) is MessageTextContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageTextContent) --> Text: {c.text.value}\")\n",
    "                for a in c.text.annotations:\n",
    "                    if type(a) is MessageTextFileCitationAnnotation:\n",
    "                        print(f\">>> Citation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        citations.append(a)\n",
    "                    elif type(a) is MessageTextFilePathAnnotation:\n",
    "                        print(f\">>> Annotation in MessageTextContent {j} of message {i}: {a}\\n\")\n",
    "                        annotations.append(a)\n",
    "            elif (type(c) is MessageImageFileContent):\n",
    "                print(f\"\\nMessage {i} / CONTENT {j} (MessageImageFileContent) --> image_file id: {c.image_file.file_id}\")\n",
    "                image_files.append(c.image_file.file_id)\n",
    "\n",
    "else:\n",
    "    print(f\"Sorry, I can't proceed because the run status is {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print annotations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Nr. of file path annotations: {len(annotations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in annotations:\n",
    "    i += 1\n",
    "    print(f\"{i} - File annotation paths: {a.text}\")\n",
    "    file_name = a.text.split('/')[-1]\n",
    "    file_id = a.file_path.file_id\n",
    "\n",
    "    #agents_client.files.save(file_id=file_id, file_name=file_name)\n",
    "    project_client.agents.files.save(file_id=file_id, file_name=file_name)\n",
    "    print(f\"\\n>>> file <{file_id}> saved as <{file_name}>\")\n",
    "    \n",
    "    # project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "    print(f\"File annotation {i} saved as file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch citations from the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Nr. of file path citations: {len(citations)}\\n\")\n",
    "\n",
    "i=0\n",
    "for a in citations:\n",
    "    i += 1\n",
    "    print(f\"{i} - citation: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and download eventual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Nr. of image contents: {len(image_files)}\\n\")\n",
    "\n",
    "i=0\n",
    "# Generate an image file for the bar chart\n",
    "for image_file in image_files:\n",
    "    i += 1\n",
    "    print(f\"{i} - Image file id: {image_file}\")\n",
    "    file_name = f\"{image_file}.png\"\n",
    "    project_client.agents.files.save(file_id=image_file, file_name=file_name)\n",
    "    print(f\"Image content {i} file to: {os.getcwd()}/{file_name}\")\n",
    "    image = mpimg.imread(f\"{os.getcwd()}/{file_name}\") # read the image\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all resources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agents = list_all_agents(client=project_client)\n",
    "print(all_agents[\"summary\"])\n",
    "\n",
    "all_threads = list_all_threads(client=project_client)\n",
    "print(all_threads[\"summary\"])\n",
    "\n",
    "all_files = list_all_files(client=project_client)\n",
    "print(all_files[\"summary\"])\n",
    "\n",
    "all_runs = list_all_runs(client=project_client)\n",
    "print(all_runs[\"summary\"])\n",
    "\n",
    "# all_runsteps=list_all_runsteps(project_client)\n",
    "# print(all_runsteps[\"summary\"])\n",
    "\n",
    "# all_messages = list_all_messages(project_client)\n",
    "# print(all_messages[\"summary\"])\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "print(all_vectorstores[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teardown for all resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all vector stores\n",
    "\n",
    "i=0\n",
    "for vector_store in all_vectorstores[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.vector_stores.delete(vector_store_id=vector_store.id)\n",
    "    print(f\"{i} - Vector store <{vector_store.id}> has been deleted\")\n",
    "\n",
    "all_vectorstores = list_all_vectorstores(client=project_client)\n",
    "\n",
    "print(f\"Vector stores deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all files\n",
    "\n",
    "i=0\n",
    "for file in all_files['content']:\n",
    "    i += 1\n",
    "    project_client.agents.files.delete(file_id=file.id)\n",
    "    print(f\"{i} - File <{file.filename}> ({file.id}) has been deleted\")\n",
    "\n",
    "all_files = list_all_files(project_client)\n",
    "\n",
    "print(f\"Files deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all threads\n",
    "\n",
    "i=0\n",
    "for thread in all_threads[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"{i} - Thread <{thread.id}> has been deleted\")\n",
    "\n",
    "all_threads = list_all_threads(project_client)\n",
    "\n",
    "print(f\"Threads deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all agents\n",
    "\n",
    "i=0\n",
    "for agent in all_agents[\"content\"]:\n",
    "    i += 1\n",
    "    project_client.agents.delete_agent(agent_id=agent.id)\n",
    "    print(f\"{i} - Agent <{agent.id}> has been deleted\")\n",
    "\n",
    "all_agents = list_all_agents(client=project_client)\n",
    "\n",
    "print(f\"Agents deleted: {i}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIC SUNT LEONES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaas",
   "language": "python",
   "name": "aaas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
